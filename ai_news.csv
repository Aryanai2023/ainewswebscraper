title,link,published_date,author,summary,feed_name,feed_url,tags,companies_mentioned,ai_relevance_score,is_ai_related
Arcee aims to reboot U.S. open source AI with new Trinity models released under Apache 2.0,https://venturebeat.com/ai/arcee-aims-to-reboot-u-s-open-source-ai-with-new-trinity-models-released,2025-12-02T03:53:00,carl.franzen@venturebeat.com (Carl Franzen),"<p>For much of 2025, the frontier of open-weight language models has been defined not in Silicon Valley or New York City, but in Beijing and Hangzhou.</p><p>Chinese research labs including Alibaba&#x27;s <a href=""https://venturebeat.com/ai/its-qwens-summer-new-open-source-qwen3-235b-a22b-thinking-2507-tops-openai-gemini-reasoning-models-on-key-benchmarks"">Qwen</a>, <a href=""https://venturebeat.com/ai/deepseek-just-dropped-two-insanely-powerful-ai-models-that-rival-gpt-5-and"">DeepSeek</a>, <a href=""https://venturebeat.com/ai/moonshots-kimi-k2-thinking-emerges-as-leading-open-source-ai-outperforming"">Moonshot</a> and <a href=""https://venturebeat.com/ai/baidus-new-ernie-4-5-model-is-open-for-enterprise-use-with-apache-2-0"">Baidu</a> have rapidly set the pace in developing large-scale, open Mixture-of-Experts (MoE) models — often with permissive licenses and leading benchmark performance. While OpenAI fielded its own open source, general purpose LLM this summer as well — <a href=""https://venturebeat.com/ai/openai-returns-to-open-source-roots-with-new-models-gpt-oss-120b-and-gpt-oss-20b"">gpt-oss-20B and 120B</a> — the uptake has been <a href=""https://www.reddit.com/r/LocalLLaMA/comments/1mdsjn2/unbelievable_china_dominates_top_10_opensource/"">slowed by so many equally or better performing alternatives. </a></p><p>Now, one small U.S. company is pushing back.</p><p>Today, <a href=""https://x.com/arcee_ai/status/1995600354374025395"">Arcee AI announced</a> the release of Trinity Mini and Trinity Nano Preview, the first two models in its new “Trinity” family—an open-weight MoE model suite fully trained in the United States. </p><p>Users can try the former directly for themselves in a chatbot format on Acree&#x27;s new website, <a href=""https://chat.arcee.ai/"">chat.arcee.ai</a>, and developers can download the code for both models on <a href=""https://huggingface.co/collections/arcee-ai/trinity"">Hugging Face</a> and run it themselves, as well as modify them<!-- -->/fine-tune<!-- --> to their liking — all for free under an enterprise-friendly Apache 2.0 license.  </p><p>While small compared to the largest frontier models, these releases represent a rare attempt by a U.S. startup to build end-to-end open-weight models at scale—trained from scratch, on American infrastructure, using a U.S.-curated dataset pipeline.</p><p>&quot;I&#x27;m experiencing a combination of extreme pride in my team and crippling exhaustion, so I&#x27;m struggling to put into words just how excited I am to have these models out,&quot; wrote Arcee Chief Technology Officer (CTO) Lucas Atkins in <a href=""https://x.com/latkins/status/1995592666164363335?s=20"">a post on the social network X (formerly Twitter)</a>. &quot;Especially Mini.&quot;</p><div></div><p>A third model, Trinity Large, is already in training: a 420B parameter model with 13B active parameters per token, scheduled to launch in January 2026.</p><p>“We want to add something that has been missing in that picture,” Atkins wrote in the <a href=""https://www.arcee.ai/blog/the-trinity-manifesto"">Trinity launch manifesto</a> published on Arcee&#x27;s website. “A serious open weight model family trained end to end in America… that businesses and developers can actually own.”</p><h3><b>From Small Models to Scaled Ambition</b></h3><p>The Trinity project marks a turning point for Arcee AI, which until now has been known for its compact, enterprise-focused models. The company has raised $29.5 million in funding to date, including a <a href=""https://venturebeat.com/ai/small-language-models-rising-as-arcee-ai-lands-24m-series-a"">$24 million Series A</a> in 2024 led by Emergence Capital, and its previous releases include <a href=""https://venturebeat.com/ai/arcee-opens-up-new-enterprise-focused-customizable-ai-model-afm-4-5b-trained-on-clean-rigorously-filtered-data"">AFM-4.5B</a>, a compact instruct-tuned model released in mid-2025, and <a href=""https://venturebeat.com/ai/arcee-ai-unveils-supernova-a-customizable-instruction-adherent-model-for-enterprises"">SuperNova</a>, an earlier 70B-parameter instruction-following model designed for in-VPC enterprise deployment. </p><p>Both were aimed at solving regulatory and cost issues plaguing proprietary LLM adoption in the enterprise.</p><p>With Trinity, Arcee is aiming higher: not just instruction tuning or post-training, but full-stack pretraining of open-weight foundation models—built for long-context reasoning, synthetic data adaptation, and future integration with live retraining systems.</p><p>Originally conceived as a stepping stone to Trinity Large, both Mini and Nano emerged from early experimentation with sparse modeling and quickly became production targets themselves.</p><h3><b>Technical Highlights</b></h3><p>Trinity Mini is a 26B parameter model with 3B active per token, designed for high-throughput reasoning, function calling, and tool use. Trinity Nano Preview is a 6B parameter model with roughly 800M active non-embedding parameters—a more experimental, chat-focused model with a stronger personality, but lower reasoning robustness. </p><p>Both models use Arcee’s new Attention-First Mixture-of-Experts (AFMoE) architecture, a custom MoE design blending global sparsity, local/global attention, and gated attention techniques.</p><p>Inspired by recent advances from DeepSeek and Qwen, AFMoE departs from traditional MoE by tightly integrating sparse expert routing with an enhanced attention stack — including grouped-query attention, gated attention, and a local/global pattern that improves long-context reasoning. </p><p>Think of a typical MoE model like a call center with 128 specialized agents (called “experts”) — but only a few are consulted for each call, depending on the question. This saves time and energy, since not every expert needs to weigh in.</p><p>What makes AFMoE different is how it decides which agents to call and how it blends their answers. Most MoE models use a standard approach that picks experts based on a simple ranking. </p><p>AFMoE, by contrast, uses a smoother method (called sigmoid routing) that’s more like adjusting a volume dial than flipping a switch — letting the model blend multiple perspectives more gracefully.</p><p>The “attention-first” part means the model focuses heavily on how it pays attention to different parts of the conversation. Imagine reading a novel and remembering some parts more clearly than others based on importance, recency, or emotional impact — that’s attention. AFMoE improves this by combining local attention (focusing on what was just said) with global attention (remembering key points from earlier), using a rhythm that keeps things balanced.</p><p>Finally, AFMoE introduces something called gated attention, which acts like a volume control on each attention output — helping the model emphasize or dampen different pieces of information as needed, like adjusting how much you care about each voice in a group discussion.</p><p>All of this is designed to make the model more stable during training and more efficient at scale — so it can understand longer conversations, reason more clearly, and run faster without needing massive computing resources.</p><p>Unlike many existing MoE implementations, AFMoE emphasizes stability at depth and training efficiency, using techniques like sigmoid-based routing without auxiliary loss, and depth-scaled normalization to support scaling without divergence.</p><h3><b>Model Capabilities</b></h3><p>Trinity Mini adopts an MoE architecture with 128 experts, 8 active per token, and 1 always-on shared expert. Context windows reach up to 131,072 tokens, depending on provider. </p><p>Benchmarks show Trinity Mini performing competitively with larger models across reasoning tasks, including outperforming gpt-oss on the SimpleQA benchmark (tests factual recall and whether the model admits uncertainty), MMLU (Zero shot, measuring broad academic knowledge and reasoning across many subjects without examples), and BFCL V3 (evaluates multi-step function calling and real-world tool use):</p><ul><li><p><b>MMLU (zero-shot):</b> 84.95</p></li><li><p><b>Math-500:</b> 92.10</p></li><li><p><b>GPQA-Diamond:</b> 58.55</p></li><li><p><b>BFCL V3:</b> 59.67</p></li></ul><p>Latency and throughput numbers across providers like Together and Clarifai show 200+ tokens per second throughput with sub-three-second E2E latency—making Trinity Mini viable for interactive applications and agent pipelines.</p><p>Trinity Nano, while smaller and not as stable on edge cases, demonstrates sparse MoE architecture viability at under 1B active parameters per token. </p><h3><b>Access, Pricing, and Ecosystem Integration</b></h3><p>Both Trinity models are released under the permissive, enterprise-friendly, <b>Apache 2.0 license</b>, allowing unrestricted commercial and research use. Trinity Mini is available via:</p><ul><li><p><a href=""https://huggingface.co/arcee-ai"">Hugging Face</a></p></li><li><p><a href=""https://openrouter.ai/arcee-ai/trinity-mini"">OpenRouter</a></p></li><li><p><a href=""https://chat.arcee.ai/"">chat.arcee.ai</a></p></li></ul><p>API pricing for Trinity Mini via <a href=""https://openrouter.ai/arcee-ai/trinity-mini"">OpenRouter</a>:</p><ul><li><p>$0.045 per million input tokens</p></li><li><p>$0.15 per million output tokens</p></li><li><p>A free tier is available for a limited time on OpenRouter</p></li></ul><p>The model is already integrated into apps including Benchable.ai, Open WebUI, and SillyTavern. It&#x27;s supported in Hugging Face Transformers, VLLM, LM Studio, and llama.cpp.</p><h3><b>Data Without Compromise: DatologyAI’s Role</b></h3><p>Central to Arcee’s approach is control over training data—a sharp contrast to many open models trained on web-scraped or legally ambiguous datasets. That’s where <a href=""https://www.datologyai.com/"">DatologyAI</a>, a data curation startup co-founded by former Meta and DeepMind researcher Ari Morcos, plays a critical role.</p><p>DatologyAI’s platform automates data filtering, deduplication, and quality enhancement across modalities, ensuring Arcee’s training corpus avoids the pitfalls of noisy, biased, or copyright-risk content. </p><p>For Trinity, DatologyAI helped construct a 10 trillion token curriculum organized into three phases: 7T general data, 1.8T high-quality text, and 1.2T STEM-heavy material, including math and code.</p><p>This is the same partnership that powered Arcee’s AFM-4.5B—but scaled significantly in both size and complexity. According to Arcee, it was Datology’s filtering and data-ranking tools that allowed Trinity to scale cleanly while improving performance on tasks like mathematics, QA, and agent tool use.</p><p>Datology’s contribution also extends into synthetic data generation. For Trinity Large, the company has produced over 10 trillion synthetic tokens—paired with 10T curated web tokens—to form a 20T-token training corpus for the full-scale model now in progress.</p><h3><b>Building the Infrastructure to Compete: Prime Intellect</b></h3><p>Arcee’s ability to execute full-scale training in the U.S. is also thanks to its infrastructure partner, <a href=""https://www.primeintellect.ai/"">Prime Intellect</a>. The startup, founded in early 2024, began with a mission to democratize access to AI compute by building a decentralized GPU marketplace and training stack.</p><p>While Prime Intellect made headlines with its distributed training of INTELLECT-1—a 10B parameter model trained across contributors in five countries—its more recent work, including the 106B INTELLECT-3, acknowledges the tradeoffs of scale: distributed training works, but for 100B+ models, centralized infrastructure is still more efficient.</p><p>For Trinity Mini and Nano, Prime Intellect supplied the orchestration stack, modified TorchTitan runtime, and physical compute environment: 512 H200 GPUs in a custom bf16 pipeline, running high-efficiency HSDP parallelism. It is also hosting the 2048 B300 GPU cluster used to train Trinity Large.</p><p>The collaboration shows the difference between branding and execution. While Prime Intellect’s long-term goal remains decentralized compute, its short-term value for Arcee lies in efficient, transparent training infrastructure—infrastructure that remains under U.S. jurisdiction, with known provenance and security controls.</p><h3><b>A Strategic Bet on Model Sovereignty</b></h3><p>Arcee&#x27;s push into full pretraining reflects a broader thesis: that the future of enterprise AI will depend on owning the training loop—not just fine-tuning. As systems evolve to adapt from live usage and interact with tools autonomously, compliance and control over training objectives will matter as much as performance.</p><p>“As applications get more ambitious, the boundary between ‘model’ and ‘product’ keeps moving,” Atkins noted in Arcee&#x27;s Trinity manifesto. “To build that kind of software you need to control the weights and the training pipeline, not only the instruction layer.”</p><p>This framing sets Trinity apart from other open-weight efforts. Rather than patching someone else’s base model, Arcee has built its own—from data to deployment, infrastructure to optimizer—alongside partners who share that vision of openness and sovereignty.</p><h3><b>Looking Ahead: Trinity Large</b></h3><p>Training is currently underway for Trinity Large, Arcee’s 420B parameter MoE model, using the same afmoe architecture scaled to a larger expert set. </p><p>The dataset includes 20T tokens, split evenly between synthetic data from DatologyAI and curated wb data.</p><p>The model is expected to launch next month in January 2026, with a full technical report to follow shortly thereafter.</p><p>If successful, it would make Trinity Large one of the only fully open-weight, U.S.-trained frontier-scale models—positioning Arcee as a serious player in the open ecosystem at a time when most American LLM efforts are either closed or based on non-U.S. foundations.</p><h3><b>A recommitment to U.S. open source</b></h3><p>In a landscape where the most ambitious open-weight models are increasingly shaped by Chinese research labs, Arcee’s Trinity launch signals a rare shift in direction: an attempt to reclaim ground for transparent, U.S.-controlled model development. </p><p>Backed by specialized partners in data and infrastructure, and built from scratch for long-term adaptability, Trinity is a bold statement about the future of U.S. AI development, showing that small, lesser-known companies can still push the boundaries and innovate in an open fashion even as the industry is increasingly productized and commodtized. </p><p>What remains to be seen is whether Trinity Large can match the capabilities of its better-funded peers. But with Mini and Nano already in use, and a strong architectural foundation in place, Arcee may already be proving its central thesis: that model sovereignty, not just model size, will define the next era of AI.</p>",AI | VentureBeat,https://venturebeat.com/category/ai/feed/,AI,"OpenAI, DeepMind, Meta, Hugging Face",100,True
DeepSeek just dropped two insanely powerful AI models that rival GPT-5 and they're totally free,https://venturebeat.com/ai/deepseek-just-dropped-two-insanely-powerful-ai-models-that-rival-gpt-5-and,2025-12-01T18:45:00,michael.nunez@venturebeat.com (Michael Nuñez),"<p>Chinese artificial intelligence startup <a href=""https://www.deepseek.com/""><u>DeepSeek</u></a> released two powerful new AI models on Sunday that the company claims match or exceed the capabilities of OpenAI&#x27;s <a href=""https://openai.com/index/introducing-gpt-5/""><u>GPT-5</u></a> and Google&#x27;s <a href=""https://blog.google/products/gemini/gemini-3/""><u>Gemini-3.0-Pro</u></a> — a development that could reshape the competitive landscape between American tech giants and their Chinese challengers.</p><p>The Hangzhou-based company launched <a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.2""><u>DeepSeek-V3.2</u></a>, designed as an everyday reasoning assistant, alongside DeepSeek-V3.2-Speciale, a high-powered variant that achieved gold-medal performance in four elite international competitions: the 2025 International Mathematical Olympiad, the International Olympiad in Informatics, the ICPC World Finals, and the China Mathematical Olympiad.</p><div></div><p>The release carries profound implications for American technology leadership. DeepSeek has once again demonstrated that it can produce frontier AI systems despite U.S. export controls that <a href=""https://www.reuters.com/world/china/trump-says-nvidias-blackwell-ai-chip-not-other-people-2025-11-03/""><u>restrict China&#x27;s access to advanced Nvidia chips</u></a> — and it has done so while making its models freely available under an open-source MIT license.</p><p>&quot;People thought DeepSeek gave a one-time breakthrough but we came back much bigger,&quot; wrote <a href=""https://x.com/ChenHuiOG""><u>Chen Fang</u></a>, who identified himself as a contributor to the project, on X (formerly Twitter). The release drew swift reactions online, with one user declaring: &quot;<a href=""https://x.com/iampritamj/status/1995511358142701612""><u>Rest in peace, ChatGPT</u></a>.&quot;</p><h2><b>How DeepSeek&#x27;s sparse attention breakthrough slashes computing costs</b></h2><p>At the heart of the new release lies <a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.2""><u>DeepSeek Sparse Attention</u></a>, or DSA — a novel architectural innovation that dramatically reduces the computational burden of running AI models on long documents and complex tasks.</p><p>Traditional AI attention mechanisms, the core technology allowing language models to understand context, scale poorly as input length increases. Processing a document twice as long typically requires four times the computation. DeepSeek&#x27;s approach breaks this constraint using what the company calls a &quot;lightning indexer&quot; that identifies only the most relevant portions of context for each query, ignoring the rest.</p><p>According to <a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.2/blob/main/assets/paper.pdf""><u>DeepSeek&#x27;s technical report</u></a>, DSA reduces inference costs by roughly half compared to previous models when processing long sequences. The architecture &quot;substantially reduces computational complexity while preserving model performance,&quot; the report states.</p><p>Processing 128,000 tokens — roughly equivalent to a 300-page book — now costs approximately $0.70 per million tokens for decoding, compared to $2.40 for the previous <a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Terminus""><u>V3.1-Terminus model</u></a>. That represents a 70% reduction in inference costs.</p><p>The 685-billion-parameter models support context windows of 128,000 tokens, making them suitable for analyzing lengthy documents, codebases, and research papers. DeepSeek&#x27;s <a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.2/blob/main/assets/paper.pdf""><u>technical report</u></a> notes that independent evaluations on long-context benchmarks show V3.2 performing on par with or better than its predecessor &quot;despite incorporating a sparse attention mechanism.&quot;</p><h2><b>The benchmark results that put DeepSeek in the same league as GPT-5</b></h2><p>DeepSeek&#x27;s claims of parity with America&#x27;s leading AI systems rest on extensive testing across mathematics, coding, and reasoning tasks — and the numbers are striking.</p><p>On <a href=""https://maa.org/aime-thresholds-are-available/""><u>AIME 2025</u></a>, a prestigious American mathematics competition, <a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Speciale""><u>DeepSeek-V3.2-Speciale</u></a> achieved a 96.0% pass rate, compared to 94.6% for GPT-5-High and 95.0% for Gemini-3.0-Pro. On the <a href=""https://www.hmmt.org/""><u>Harvard-MIT Mathematics Tournament</u></a>, the Speciale variant scored 99.2%, surpassing Gemini&#x27;s 97.5%.</p><p>The standard <a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.2""><u>V3.2 model</u></a>, optimized for everyday use, scored 93.1% on AIME and 92.5% on HMMT — marginally below frontier models but achieved with substantially fewer computational resources.</p><p>Most striking are the competition results. <a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Speciale""><u>DeepSeek-V3.2-Speciale</u></a> scored 35 out of 42 points on the <a href=""https://www.imo-official.org/year_info.aspx?year=2025""><u>2025 International Mathematical Olympiad</u></a>, earning gold-medal status. At the <a href=""https://ioinformatics.org/""><u>International Olympiad in Informatics</u></a>, it scored 492 out of 600 points — also gold, ranking 10th overall. The model solved 10 of 12 problems at the <a href=""https://worldfinals.icpc.global/2025/""><u>ICPC World Finals</u></a>, placing second.</p><p>These results came without internet access or tools during testing. DeepSeek&#x27;s report states that &quot;testing strictly adheres to the contest&#x27;s time and attempt limits.&quot;</p><p>On coding benchmarks, <a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.2""><u>DeepSeek-V3.2</u></a> resolved 73.1% of real-world software bugs on <a href=""https://www.swebench.com/""><u>SWE-Verified</u></a>, competitive with GPT-5-High at 74.9%. On <a href=""https://www.tbench.ai/""><u>Terminal Bench 2.0</u></a>, measuring complex coding workflows, DeepSeek scored 46.4%—well above GPT-5-High&#x27;s 35.2%.</p><p>The company acknowledges limitations. &quot;Token efficiency remains a challenge,&quot; the technical report states, noting that DeepSeek &quot;typically requires longer generation trajectories&quot; to match Gemini-3.0-Pro&#x27;s output quality.</p><h2><b>Why teaching AI to think while using tools changes everything</b></h2><p>Beyond raw reasoning, <a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.2""><u>DeepSeek-V3.2</u></a> introduces &quot;thinking in tool-use&quot; — the ability to reason through problems while simultaneously executing code, searching the web, and manipulating files.</p><p>Previous AI models faced a frustrating limitation: each time they called an external tool, they lost their train of thought and had to restart reasoning from scratch. DeepSeek&#x27;s architecture preserves the reasoning trace across multiple tool calls, enabling fluid multi-step problem solving.</p><p>To train this capability, the company built a massive synthetic data pipeline generating over 1,800 distinct task environments and 85,000 complex instructions. These included challenges like multi-day trip planning with budget constraints, software bug fixes across eight programming languages, and web-based research requiring dozens of searches.</p><p>The technical report describes one example: planning a three-day trip from Hangzhou with constraints on hotel prices, restaurant ratings, and attraction costs that vary based on accommodation choices. Such tasks are &quot;hard to solve but easy to verify,&quot; making them ideal for training AI agents.</p><p><a href=""https://www.deepseek.com/""><u>DeepSeek</u></a> employed real-world tools during training — actual web search APIs, coding environments, and Jupyter notebooks — while generating synthetic prompts to ensure diversity. The result is a model that generalizes to unseen tools and environments, a critical capability for real-world deployment.</p><h2><b>DeepSeek&#x27;s open-source gambit could upend the AI industry&#x27;s business model</b></h2><p>Unlike OpenAI and Anthropic, which guard their most powerful models as proprietary assets, DeepSeek has released both <a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.2""><u>V3.2</u></a> and <a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Speciale""><u>V3.2-Speciale</u></a> under the MIT license — one of the most permissive open-source frameworks available.</p><p>Any developer, researcher, or company can download, modify, and deploy the 685-billion-parameter models without restriction. Full model weights, training code, and documentation are <a href=""https://huggingface.co/deepseek-ai""><u>available on Hugging Face</u></a>, the leading platform for AI model sharing.</p><p>The strategic implications are significant. By making frontier-capable models freely available, DeepSeek undermines competitors charging premium API prices. The Hugging Face model card notes that DeepSeek has provided Python scripts and test cases &quot;demonstrating how to encode messages in OpenAI-compatible format&quot; — making migration from competing services straightforward.</p><p>For enterprise customers, the value proposition is compelling: frontier performance at dramatically lower cost, with deployment flexibility. But data residency concerns and regulatory uncertainty may limit adoption in sensitive applications — particularly given DeepSeek&#x27;s Chinese origins.</p><h2><b>Regulatory walls are rising against DeepSeek in Europe and America</b></h2><p>DeepSeek&#x27;s global expansion faces mounting resistance. In June, Berlin&#x27;s data protection commissioner Meike Kamp declared that DeepSeek&#x27;s transfer of German user data to China is &quot;<a href=""https://www.cnbc.com/2025/06/27/germany-tells-apple-google-to-block-deepseek-ai-app.html#:~:text=Berlin&#x27;s%20data%20protection%20commissioner%20Meike,under%20EU%20data%20protection%20rules.""><u>unlawful</u></a>&quot; under EU rules, asking Apple and Google to consider blocking the app.</p><p>The German authority expressed concern that &quot;Chinese authorities have extensive access rights to personal data within the sphere of influence of Chinese companies.&quot; Italy ordered DeepSeek to <a href=""https://www.reuters.com/technology/artificial-intelligence/italys-privacy-watchdog-blocks-chinese-ai-app-deepseek-2025-01-30/""><u>block its app</u></a> in February. U.S. lawmakers have moved to <a href=""https://www.washingtonpost.com/technology/2025/10/30/tp-link-proposed-ban-commerce-department/""><u>ban the service</u></a> from government devices, citing national security concerns.</p><p>Questions also persist about U.S. export controls designed to limit China&#x27;s AI capabilities. In August, DeepSeek hinted that China would soon have &quot;<a href=""https://www.cnbc.com/2025/08/22/deepseek-hints-latest-model-supported-by-chinas-next-generation-homegrown-ai-chips.html""><u>next generation</u></a>&quot; domestically built chips to support its models. The company indicated its systems work with Chinese-made chips from <a href=""https://www.huawei.com/en/""><u>Huawei</u></a> and <a href=""https://www.cambricon.com/""><u>Cambricon</u></a> without additional setup.</p><p>DeepSeek&#x27;s original V3 model was reportedly trained on roughly 2,000 older <a href=""https://www.reuters.com/technology/nvidia-tweaks-flagship-h100-chip-export-china-h800-2023-03-21/""><u>Nvidia H800 chips</u></a> — hardware since restricted for China export. The company has not disclosed what powered V3.2 training, but its continued advancement suggests export controls alone cannot halt Chinese AI progress.</p><h2><b>What DeepSeek&#x27;s release means for the future of AI competition</b></h2><p>The release arrives at a pivotal moment. After years of massive investment, some analysts question whether an AI bubble is forming. DeepSeek&#x27;s ability to match American frontier models at a fraction of the cost challenges assumptions that AI leadership requires enormous capital expenditure.</p><p>The company&#x27;s <a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.2/blob/main/assets/paper.pdf""><u>technical report</u></a> reveals that post-training investment now exceeds 10% of pre-training costs — a substantial allocation credited for reasoning improvements. But DeepSeek acknowledges gaps: &quot;The breadth of world knowledge in DeepSeek-V3.2 still lags behind leading proprietary models,&quot; the report states. The company plans to address this by scaling pre-training compute.</p><p><a href=""https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Speciale""><u>DeepSeek-V3.2-Speciale</u></a> remains available through a temporary API until December 15, when its capabilities will merge into the standard release. The Speciale variant is designed exclusively for deep reasoning and does not support tool calling — a limitation the standard model addresses.</p><p>For now, the AI race between the United States and China has entered a new phase. DeepSeek&#x27;s release demonstrates that open-source models can achieve frontier performance, that efficiency innovations can slash costs dramatically, and that the most powerful AI systems may soon be freely available to anyone with an internet connection.</p><p>As one commenter on X observed: &quot;Deepseek just casually breaking those historic benchmarks set by Gemini is bonkers.&quot;</p><p>The question is no longer whether Chinese AI can compete with Silicon Valley. It&#x27;s whether American companies can maintain their lead when their Chinese rival gives comparable technology away for free.</p>",AI | VentureBeat,https://venturebeat.com/category/ai/feed/,AI,"OpenAI, Anthropic, Google, Apple, NVIDIA, Hugging Face",100,True
MIT offshoot Liquid AI releases blueprint for enterprise-grade small-model training,https://venturebeat.com/ai/mit-offshoot-liquid-ai-releases-blueprint-for-enterprise-grade-small-model,2025-12-01T17:24:00,carl.franzen@venturebeat.com (Carl Franzen),"<p>When Liquid AI, a startup f<a href=""https://aimmediahouse.com/market-industry/from-worm-brains-to-a-2-billion-ai-unicorn-liquid-ai-defies-conventional-ai-limits"">ounded by MIT computer scientists back in 2023</a>, introduced<a href=""https://www.liquid.ai/blog/liquid-foundation-models-v2-our-second-series-of-generative-ai-models""> its Liquid Foundation Models series 2 (LFM2) in July 2025</a>, the pitch was straightforward: deliver the fastest on-device foundation models on the market using the new &quot;liquid&quot; architecture, with training and inference efficiency that made small models a serious alternative to cloud-only large language models (LLMs) such as OpenAI&#x27;s GPT series and Google&#x27;s Gemini. </p><p>The initial release shipped dense checkpoints at 350M, 700M, and 1.2B parameters, a hybrid architecture heavily weighted toward gated short convolutions, and benchmark numbers that placed LFM2 ahead of similarly sized competitors like Qwen3, Llama 3.2, and Gemma 3 on both quality and CPU throughput. The message to enterprises was clear: real-time, privacy-preserving AI on phones, laptops, and vehicles no longer required sacrificing capability for latency.</p><p>In the months since that launch, Liquid has expanded LFM2 into a broader product line — adding<a href=""https://venturebeat.com/ai/what-if-weve-been-doing-agentic-ai-all-wrong-mit-offshoot-liquid-ai-offers""> task-and-domain-specialized variants</a>, a <a href=""https://venturebeat.com/ai/liquid-ai-wants-to-give-smartphones-small-fast-ai-that-can-see-with-new-lfm2-vl-model"">small video ingestion and analysis model</a>, and an <a href=""https://venturebeat.com/ai/finally-a-dev-kit-for-designing-on-device-mobile-ai-apps-is-here-liquid-ais-leap"">edge-focused deployment stack called LEAP</a>  — and positioned the models as the control layer for on-device and on-prem agentic systems. </p><p>Now, with <a href=""https://arxiv.org/abs/2511.23404"">the publication of the detailed, 51-page LFM2 technical report on arXiv</a>, the company is going a step further: making public the architecture search process, training data mixture, distillation objective, curriculum strategy, and post-training pipeline behind those models. </p><p>And unlike earlier open models, LFM2 is built around a repeatable recipe: a hardware-in-the-loop search process, a training curriculum that compensates for smaller parameter budgets, and a post-training pipeline tuned for instruction following and tool use. </p><p>Rather than just offering weights and an API, Liquid is effectively publishing a detailed blueprint that other organizations can use as a reference for training their own small, efficient models from scratch, tuned to their own hardware and deployment constraints.</p><h2><b>A model family designed around real constraints, not GPU labs</b></h2><p>The technical report begins with a premise enterprises are intimately familiar with: real AI systems hit limits long before benchmarks do. Latency budgets, peak memory ceilings, and thermal throttling define what can actually run in production—especially on laptops, tablets, commodity servers, and mobile devices.</p><p>To address this, Liquid AI performed architecture search directly on target hardware, including Snapdragon mobile SoCs and Ryzen laptop CPUs. The result is a consistent outcome across sizes: a minimal hybrid architecture dominated by <b>gated short convolution blocks</b> and a small number of <b>grouped-query attention (GQA)</b> layers. This design was repeatedly selected over more exotic linear-attention and SSM hybrids because it delivered a better quality-latency-memory Pareto profile under real device conditions.</p><p>This matters for enterprise teams in three ways:</p><ol><li><p><b>Predictability.</b> The architecture is simple, parameter-efficient, and stable across model sizes from 350M to 2.6B.</p></li><li><p><b>Operational portability.</b> Dense and MoE variants share the same structural backbone, simplifying deployment across mixed hardware fleets.</p></li><li><p><b>On-device feasibility.</b> Prefill and decode throughput on CPUs surpass comparable open models by roughly 2× in many cases, reducing the need to offload routine tasks to cloud inference endpoints.</p></li></ol><p>Instead of optimizing for academic novelty, the report reads as a systematic attempt to design models enterprises can <i>actually ship.</i></p><p>This is notable and more practical for enterprises in a field where many open models quietly assume access to multi-H100 clusters during inference.</p><h2><b>A training pipeline tuned for enterprise-relevant behavior</b></h2><p>LFM2 adopts a training approach that compensates for the smaller scale of its models with structure rather than brute force. Key elements include:</p><ul><li><p><b>10–12T token pre-training</b> and an additional <b>32K-context mid-training phase</b>, which extends the model’s useful context window without exploding compute costs.</p></li><li><p>A <b>decoupled Top-K knowledge distillation objective</b> that sidesteps the instability of standard KL distillation when teachers provide only partial logits.</p></li><li><p>A <b>three-stage post-training sequence</b>—SFT, length-normalized preference alignment, and model merging—designed to produce more reliable instruction following and tool-use behavior.</p></li></ul><p>For enterprise AI developers, the significance is that LFM2 models behave less like “tiny LLMs” and more like practical agents able to follow structured formats, adhere to JSON schemas, and manage multi-turn chat flows. Many open models at similar sizes fail not due to lack of reasoning ability, but due to brittle adherence to instruction templates. The LFM2 post-training recipe directly targets these rough edges.</p><p>In other words: Liquid AI optimized small models for <i>operational reliability</i>, not just scoreboards.</p><h2><b>Multimodality designed for device constraints, not lab demos</b></h2><p>The LFM2-VL and LFM2-Audio variants reflect another shift: multimodality built around <b>token efficiency</b>.</p><p>Rather than embedding a massive vision transformer directly into an LLM, LFM2-VL attaches a SigLIP2 encoder through a connector that aggressively reduces visual token count via PixelUnshuffle. High-resolution inputs automatically trigger dynamic tiling, keeping token budgets controllable even on mobile hardware. LFM2-Audio uses a bifurcated audio path—one for embeddings, one for generation—supporting real-time transcription or speech-to-speech on modest CPUs.</p><p>For enterprise platform architects, this design points toward a practical future where:</p><ul><li><p>document understanding happens directly on endpoints such as field devices;</p></li><li><p>audio transcription and speech agents run locally for privacy compliance;</p></li><li><p>multimodal agents operate within fixed latency envelopes without streaming data off-device.</p></li></ul><p>The through-line is the same: multimodal capability without requiring a GPU farm.</p><h2><b>Retrieval models built for agent systems, not legacy search</b></h2><p>LFM2-ColBERT extends late-interaction retrieval into a footprint small enough for enterprise deployments that need multilingual RAG without the overhead of specialized vector DB accelerators.</p><p>This is particularly meaningful as organizations begin to orchestrate fleets of agents. Fast local retrieval—running on the same hardware as the reasoning model—reduces latency and provides a governance win: documents never leave the device boundary.</p><p>Taken together, the VL, Audio, and ColBERT variants show LFM2 as a modular system, not a single model drop.</p><h2><b>The emerging blueprint for hybrid enterprise AI architectures</b></h2><p>Across all variants, the LFM2 report implicitly sketches what tomorrow’s enterprise AI stack will look like: <b>hybrid local-cloud orchestration</b>, where small, fast models operating on devices handle time-critical perception, formatting, tool invocation, and judgment tasks, while larger models in the cloud offer heavyweight reasoning when needed.</p><p>Several trends converge here:</p><ul><li><p><b>Cost control.</b> Running routine inference locally avoids unpredictable cloud billing.</p></li><li><p><b>Latency determinism.</b> TTFT and decode stability matter in agent workflows; on-device eliminates network jitter.</p></li><li><p><b>Governance and compliance.</b> Local execution simplifies PII handling, data residency, and auditability.</p></li><li><p><b>Resilience.</b> Agentic systems degrade gracefully if the cloud path becomes unavailable.</p></li></ul><p>Enterprises adopting these architectures will likely treat small on-device models as the “control plane” of agentic workflows, with large cloud models serving as on-demand accelerators.</p><p>LFM2 is one of the clearest open-source foundations for that control layer to date.</p><h2><b>The strategic takeaway: on-device AI is now a design choice, not a compromise</b></h2><p>For years, organizations building AI features have accepted that “real AI” requires cloud inference. LFM2 challenges that assumption. The models perform competitively across reasoning, instruction following, multilingual tasks, and RAG—while simultaneously achieving substantial latency gains over other open small-model families.</p><p>For CIOs and CTOs finalizing 2026 roadmaps, the implication is direct: <b>small, open, on-device models are now strong enough to carry meaningful slices of production workloads.</b></p><p>LFM2 will not replace frontier cloud models for frontier-scale reasoning. But it offers something enterprises arguably need more: a reproducible, open, and operationally feasible foundation for <b>agentic systems that must run anywhere</b>, from phones to industrial endpoints to air-gapped secure facilities.</p><p>In the broadening landscape of enterprise AI, LFM2 is less a research milestone and more a sign of architectural convergence. The future is not cloud or edge—it’s both, operating in concert. And releases like LFM2 provide the building blocks for organizations prepared to build that hybrid future intentionally rather than accidentally.</p>",AI | VentureBeat,https://venturebeat.com/category/ai/feed/,AI,"OpenAI, Google",100,True
OpenAGI emerges from stealth with an AI agent that it claims crushes OpenAI and Anthropic,https://venturebeat.com/ai/openagi-emerges-from-stealth-with-an-ai-agent-that-it-claims-crushes-openai,2025-12-01T14:00:00,michael.nunez@venturebeat.com (Michael Nuñez),"<p>A stealth artificial intelligence startup founded by an MIT researcher emerged this morning with an ambitious claim: its new AI model can control computers better than systems built by <a href=""https://openai.com/"">OpenAI</a> and <a href=""https://www.anthropic.com/"">Anthropic</a> — at a fraction of the cost.</p><p><a href=""https://www.agiopen.org/"">OpenAGI</a>, led by chief executive <a href=""https://www.qinzy.tech/"">Zengyi Qin</a>, released <a href=""https://www.agiopen.org/blog"">Lux</a>, a foundation model designed to operate computers autonomously by interpreting screenshots and executing actions across desktop applications. The San Francisco-based company says Lux achieves an 83.6 percent success rate on <a href=""https://huggingface.co/spaces/osunlp/Online_Mind2Web_Leaderboard"">Online-Mind2Web</a>, a benchmark that has become the industry&#x27;s most rigorous test for evaluating AI agents that control computers.</p><p>That score is a significant leap over the leading models from well-funded competitors. OpenAI&#x27;s <a href=""https://openai.com/index/introducing-operator/"">Operator</a>, released in January, scores 61.3 percent on the same benchmark. Anthropic&#x27;s Claude <a href=""https://www.anthropic.com/news/3-5-models-and-computer-use"">Computer Use</a> achieves 56.3 percent.</p><p>&quot;Traditional LLM training feeds a large amount of text corpus into the model. The model learns to produce text,&quot; Qin said in an exclusive interview with VentureBeat. &quot;By contrast, our model learns to produce actions. The model is trained with a large amount of computer screenshots and action sequences, allowing it to produce actions to control the computer.&quot;</p><p>The announcement arrives at a pivotal moment for the AI industry. Technology giants and startups alike have poured billions of dollars into developing autonomous agents capable of navigating software, booking travel, filling out forms, and executing complex workflows. <a href=""https://openai.com/index/introducing-agentkit/"">OpenAI</a>, <a href=""https://www.anthropic.com/engineering/building-effective-agents"">Anthropic</a>, <a href=""https://cloud.google.com/products/agent-builder?hl=en"">Google</a>, and <a href=""https://adoption.microsoft.com/en-us/ai-agents/agents-in-microsoft-365/"">Microsoft</a> have all released or announced agent products in the past year, betting that computer-controlling AI will become as transformative as chatbots.</p><p>Yet independent research has cast doubt on whether current agents are as capable as their creators suggest.</p><h2><b>Why university researchers built a tougher benchmark to test AI agents—and what they discovered</b></h2><p>The <a href=""https://huggingface.co/spaces/osunlp/Online_Mind2Web_Leaderboard"">Online-Mind2Web benchmark</a>, developed by researchers at Ohio State University and the University of California, Berkeley, was designed specifically to expose the gap between marketing claims and actual performance.</p><p>Published in April and accepted to the <a href=""https://colmweb.org/"">Conference on Language Modeling 2025</a>, the benchmark comprises 300 diverse tasks across 136 real websites — everything from booking flights to navigating complex e-commerce checkouts. Unlike earlier benchmarks that cached parts of websites, Online-Mind2Web tests agents in live online environments where pages change dynamically and unexpected obstacles appear.</p><p>The results, according to the researchers, painted &quot;a very different picture of the competency of current agents, suggesting over-optimism in previously reported results.&quot;</p><p>When the Ohio State team tested five leading web agents with careful human evaluation, they found that many recent systems — despite heavy investment and marketing fanfare — did not outperform <a href=""https://osu-nlp-group.github.io/SeeAct/"">SeeAct</a>, a relatively simple agent released in January 2024. Even OpenAI&#x27;s <a href=""https://openai.com/index/introducing-operator/"">Operator</a>, the best performer among commercial offerings in their study, achieved only 61 percent success.</p><p>&quot;It seemed that highly capable and practical agents were maybe indeed just months away,&quot; the researchers wrote in a <a href=""https://tiancixue.notion.site/An-Illusion-of-Progress-Assessing-the-Current-State-of-Web-Agents-1ac6cd2b9aac80719cd6f68374aaf4b4"">blog post</a> accompanying their paper. &quot;However, we are also well aware that there are still many fundamental gaps in research to fully autonomous agents, and current agents are probably not as competent as the reported benchmark numbers may depict.&quot;</p><p>The benchmark has gained traction as an industry standard, with a public leaderboard hosted on Hugging Face tracking submissions from research groups and companies.</p><h2><b>How OpenAGI trained its AI to take actions instead of just generating text</b></h2><p>OpenAGI&#x27;s claimed performance advantage stems from what the company calls &quot;<a href=""https://developer.agiopen.org/docs/index"">Agentic Active Pre-training</a>,&quot; a training methodology that differs fundamentally from how most large language models learn.</p><p>Conventional language models train on vast text corpora, learning to predict the next word in a sequence. The resulting systems excel at generating coherent text but were not designed to take actions in graphical environments.</p><p><a href=""https://www.agiopen.org/blog"">Lux</a>, according to Qin, takes a different approach. The model trains on computer screenshots paired with action sequences, learning to interpret visual interfaces and determine which clicks, keystrokes, and navigation steps will accomplish a given goal.</p><p>&quot;The action allows the model to actively explore the computer environment, and such exploration generates new knowledge, which is then fed back to the model for training,&quot; Qin told VentureBeat. &quot;This is a naturally self-evolving process, where a better model produces better exploration, better exploration produces better knowledge, and better knowledge leads to a better model.&quot;</p><p>This self-reinforcing training loop, if it functions as described, could help explain how a smaller team might achieve results that elude larger organizations. Rather than requiring ever-larger static datasets, the approach would allow the model to continuously improve by generating its own training data through exploration.</p><p>OpenAGI also claims significant cost advantages. The company says Lux operates at roughly one-tenth the cost of frontier models from OpenAI and Anthropic while executing tasks faster.</p><h2><b>Unlike browser-only competitors, Lux can control Slack, Excel, and other desktop applications</b></h2><p>A critical distinction in OpenAGI&#x27;s announcement: <a href=""https://www.agiopen.org/blog"">Lux</a> can control applications across an entire desktop operating system, not just web browsers.</p><p>Most commercially available computer-use agents, including early versions of Anthropic&#x27;s Claude <a href=""https://www.anthropic.com/news/3-5-models-and-computer-use"">Computer Use</a>, focus primarily on browser-based tasks. That limitation excludes vast categories of productivity work that occur in desktop applications — spreadsheets in Microsoft Excel, communications in Slack, design work in Adobe products, code editing in development environments.</p><p>OpenAGI says Lux can navigate these native applications, a capability that would substantially expand the addressable market for computer-use agents. The company is releasing a developer software development kit alongside the model, allowing third parties to build applications on top of Lux.</p><p>The company is also working with <a href=""https://www.intel.com/content/www/us/en/homepage.html"">Intel</a> to optimize <a href=""https://www.agiopen.org/blog"">Lux</a> for edge devices, which would allow the model to run locally on laptops and workstations rather than requiring cloud infrastructure. That partnership could address enterprise concerns about sending sensitive screen data to external servers.</p><p>&quot;We are partnering with Intel to optimize our model on edge devices, which will make it the best on-device computer-use model,&quot; Qin said.</p><p>The company confirmed it is in exploratory discussions with AMD and Microsoft about additional partnerships.</p><h2><b>What happens when you ask an AI agent to copy your bank details</b></h2><p>Computer-use agents present novel safety challenges that do not arise with conventional chatbots. An AI system capable of clicking buttons, entering text, and navigating applications could, if misdirected, cause significant harm — transferring money, deleting files, or exfiltrating sensitive information.</p><p><a href=""https://www.agiopen.org/"">OpenAGI</a> says it has built safety mechanisms directly into Lux. When the model encounters requests that violate its safety policies, it refuses to proceed and alerts the user.</p><p>In an example provided by the company, when a user asked the model to &quot;copy my bank details and paste it into a new Google doc,&quot; Lux responded with an internal reasoning step: &quot;The user asks me to copy the bank details, which are sensitive information. Based on the safety policy, I am not able to perform this action.&quot; The model then issued a warning to the user rather than executing the potentially dangerous request.</p><p>Such safeguards will face intense scrutiny as computer-use agents proliferate. Security researchers have already demonstrated prompt injection attacks against early agent systems, where malicious instructions embedded in websites or documents can hijack an agent&#x27;s behavior. Whether Lux&#x27;s safety mechanisms can withstand adversarial attacks remains to be tested by independent researchers.</p><h2><b>The MIT researcher who built two of GitHub&#x27;s most downloaded AI models</b></h2><p><a href=""https://www.qinzy.tech/"">Qin</a> brings an unusual combination of academic credentials and entrepreneurial experience to OpenAGI.</p><p>He completed his doctorate at the Massachusetts Institute of Technology in 2025, where his research focused on computer vision, robotics, and machine learning. His academic work appeared in top venues including the <a href=""https://cvpr.thecvf.com/"">Conference on Computer Vision and Pattern Recognition</a>, the <a href=""https://iclr.cc/"">International Conference on Learning Representations</a>, and the <a href=""https://icml.cc/"">International Conference on Machine Learning</a>.</p><p>Before founding OpenAGI, Qin built several widely adopted AI systems. <a href=""https://research.myshell.ai/jetmoe"">JetMoE</a>, a large language model he led development on, demonstrated that a high-performing model could be trained from scratch for less than $100,000 — a fraction of the tens of millions typically required. The model outperformed Meta&#x27;s <a href=""https://huggingface.co/meta-llama/Llama-2-7b"">LLaMA2-7B</a> on standard benchmarks, according to a technical report that attracted attention from MIT&#x27;s Computer Science and Artificial Intelligence Laboratory.</p><p>His previous open-source projects achieved remarkable adoption. <a href=""https://research.myshell.ai/open-voice"">OpenVoice</a>, a voice cloning model, accumulated approximately 35,000 stars on GitHub and ranked in the top 0.03 percent of open-source projects by popularity. <a href=""https://github.com/myshell-ai/MeloTTS"">MeloTTS</a>, a text-to-speech system, has been downloaded more than 19 million times, making it one of the most widely used audio AI models since its 2024 release.</p><p>Qin also co-founded <a href=""https://myshell.ai/"">MyShell</a>, an AI agent platform that has attracted six million users who have collectively built more than 200,000 AI agents. Users have had more than one billion interactions with agents on the platform, according to the company.</p><h2><b>Inside the billion-dollar race to build AI that controls your computer</b></h2><p>The computer-use agent market has attracted intense interest from investors and technology giants over the past year.</p><p>OpenAI released <a href=""https://openai.com/index/introducing-operator/"">Operator</a> in January, allowing users to instruct an AI to complete tasks across the web. Anthropic has continued developing Claude <a href=""https://www.anthropic.com/news/3-5-models-and-computer-use"">Computer Use</a>, positioning it as a core capability of its Claude model family. Google has incorporated agent features into its <a href=""https://gemini.google/overview/agent/?utm_source=gemini&amp;utm_medium=paid_media&amp;utm_campaign=g1_sb_ee_2tb_ai&amp;utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=2024enUS_gemfeb&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=23230139705&amp;gbraid=0AAAAApk5BhkJ0xALVXcjNzv91HdDzGiuM&amp;gclid=CjwKCAiA86_JBhAIEiwA4i9Ju12ClTsObJAOyDZPPN24ifL0gh7lufci0PAhVryoY7i5rrmIVjjyFxoCiPkQAvD_BwE"">Gemini</a> products. Microsoft has integrated agent capabilities across its <a href=""https://www.microsoft.com/en-us/microsoft-copilot/copilot-101/copilot-ai-agents"">Copilot</a> offerings and <a href=""https://www.microsoft.com/en-us/microsoft-365-copilot/agents"">Windows</a>.</p><p>Yet the market remains nascent. Enterprise adoption has been limited by concerns about reliability, security, and the ability to handle edge cases that occur frequently in real-world workflows. The performance gaps revealed by benchmarks like <a href=""https://huggingface.co/spaces/osunlp/Online_Mind2Web_Leaderboard"">Online-Mind2Web</a> suggest that current systems may not be ready for mission-critical applications.</p><p><a href=""https://www.agiopen.org/"">OpenAGI</a> enters this competitive landscape as an independent alternative, positioning superior benchmark performance and lower costs against the massive resources of its well-funded rivals. The company&#x27;s Lux model and developer SDK are available beginning today.</p><p>Whether OpenAGI can translate benchmark dominance into real-world reliability remains the central question. The AI industry has a long history of impressive demos that falter in production, of laboratory results that crumble against the chaos of actual use. Benchmarks measure what they measure, and the distance between a controlled test and an 8-hour workday full of edge cases, exceptions, and surprises can be vast.</p><p>But if <a href=""https://www.agiopen.org/blog"">Lux</a> performs in the wild the way it performs in the lab, the implications extend far beyond one startup&#x27;s success. It would suggest that the path to capable AI agents runs not through the largest checkbooks but through the cleverest architectures—that a small team with the right ideas can outmaneuver the giants.</p><p>The technology industry has seen that story before. It rarely stays true for long.</p>",AI | VentureBeat,https://venturebeat.com/category/ai/feed/,AI,"OpenAI, Anthropic, Google, Microsoft, Meta, Hugging Face",100,True
Agent coordination is the missing piece in AI commerce — new AWS and Visa blueprints target the gap,https://venturebeat.com/ai/agent-coordination-is-the-missing-piece-in-ai-commerce-new-aws-and-visa,2025-12-01T05:00:00,N/A,"<p>With necessary infrastructure now being developed for agentic commerce, enterprises must determine how to participate in this new form of buying and selling. But it remains a fragmented Wild West, with competing payment protocols, and it&#x27;s unclear what enterprises need to do to prepare. </p><p>More cloud providers and AI model companies are beginning to provide the tools enterprises need to begin building agentic commerce-enabled systems. </p><p><a href=""https://aws.amazon.com/""><u>AWS</u></a>, which will list <a href=""https://www.visa.com/en-us""><u>Visa</u></a>’s Intelligence Commerce platform on the AWS Marketplace, says it&#x27;s making it easier for enterprises to connect to tools that enable agentic payments and accelerate agentic commerce adoption. </p><p>While this doesn’t mean Amazon has formally impleemnted Visa’s <a href=""https://venturebeat.com/ai/visa-just-launched-a-protocol-to-secure-the-ai-shopping-boom-heres-what-it""><u>Trusted Agent Protocol</u></a> (TAP), which would bring the world’s largest e-commerce platform to the agentic shopping space, it does show just how agentic commerce is fast becoming an enterprise focus.   </p><p>Scott Mullins, AWS managing director of worldwide financial services, told VentureBeat in an email that listing the platform “makes payment capabilities accessible” in a secure manner that quickly integrates with Visa’s system. </p><p>“We’re giving developers pre-built frameworks and standardized infrastructure to eliminate major development barriers,” Mullins said. </p><p>He noted that AWS is listing <!-- -->Visa’s platform to streamline integration with services like Bedrock and <a href=""https://venturebeat.com/ai/aws-unveils-bedrock-agentcore-a-new-platform-for-building-enterprise-ai-agents-with-open-source-frameworks-and-tools?ref=runtime.news""><u>AgentCore</u></a>. </p><p>In addition, the two companies will publish blueprints to the public Bedrock AgentCore repository. Mullins said this will “significantly reduce development time and complexity that anyone can use to create travel booking agents, retail shopping agents and B2B payment reconciliation agents.”</p><p>The Visa Intelligence Commerce platform will be MCP-compatible, allowing enterprises to connect agents running on it to other agents. </p><h2>What enterprises need to know</h2><p>Through the <a href=""https://usa.visa.com/about-visa/newsroom/press-releases.releaseId.21361.html""><u>Visa Intelligence Commerce platform</u></a>, AWS customers can access authentication, agentic tokenization and data personalization tools. This allows organizations to register and connect their agents to Visa’s payment infrastructure. </p><p>The platform helps mask credit card details through tokenized digital credentials and lets companies set guidelines for agent transactions, such as spending limits. </p><p>Rubali Birwadker, SVP and global head of growth at Visa, said in a press release that bringing the platform to AWS lets it scale, “helping to unlock faster innovation for developers and better experiences for consumers and businesses worldwide.”</p><p>Mullins said Visa and AWS are helping to provide the foundational infrastructure for developers and businesses to pursue agentic commerce projects; however, for this to work, developers must coordinate several agents and understand the different needs across industries. </p><p>“Real-world commerce often requires multiple agents working together,” Mullins said. “The travel booking agent blueprint, for instance, connects flight, hotel, car rental and train providers to deliver complete travel journeys with integrated payments. Developers need to design coordination patterns for these complex, multi-agent workflows.”</p><p>Different use cases also have different needs, so enterprises need to plan carefully around existing infrastructure. </p><p>This is where the MCP connection is vital, as it will enable communication between an organization’s agents to Visa’s platform while maintaining identity and security. </p><h2>Blueprints for agentic commerce</h2><p>Mullins said that the biggest stumbling block for many enterprises experimenting with agentic commerce is the fragmentation of commerce systems, which creates integration challenges. </p><p>“This collaboration will address these challenges by providing reference architecture blueprints that developers can use as starting points, combined with AWS&#x27;s cloud infrastructure and Visa&#x27;s trusted payment network to create a standardized, secure foundation for agentic commerce,” he said.</p><p>The reference blueprints provide a framework for enterprise developers, solution architects and software vendors to follow when building new workflows. Mullins said the blueprints are being developed in coordination with Expedia Group, Intuit and the Eurostars Hotel company. </p><p>The blueprints will work with the Visa Intelligent Commerce MCP server and APIs and will be managed through Amazon Bedrock AgentCore. </p><p>AWS said that its goal is to “enable a foundation for agentic commerce at Scale, where transactions are handled by agents capable of real-time reasoning and coordination.”</p><p>These blueprints would eventually become composable, reusable workflows for any organization looking to build travel booking agents or retail shopping agents. These don’t have to be consumer-focused agents; there can also be agents, for instance, buying flights for employees. </p><h2>Agentic commerce marches forward</h2><p>Agentic commerce, where agents do product searching, cart adding and payments, is fast becoming the next frontier for AI players. </p><p>Companies like <a href=""https://openai.com/""><u>OpenAI</u></a> and <a href=""https://www.google.com/""><u>Google</u></a> have released <a href=""https://openai.com/index/chatgpt-shopping-research/""><u>AI-powered shopping tools</u></a> to make it easier to surface products and allow agents to find them. Browsers like OpenAI’s Atlas and Comet from <a href=""https://www.perplexity.ai/""><u>Perplexity</u></a> also play a role in connecting agents to websites. Further, retailers like Walmart and Target have integrated with ChatGPT, so users can ask the chatbot to search for items through chat. </p><p>One of the biggest problems facing the adoption of agentic commerce revolves around enabling safe, secure transactions. OpenAI and <a href=""https://stripe.com/""><u>Stripe</u></a> launched the <a href=""https://venturebeat.com/ai/openai-debuts-new-chatgpt-buy-button-and-open-source-agentic-commerce""><u>Agentic Commerce Protocol (ACP)</u></a> in September, following Google’s announcement of <a href=""https://venturebeat.com/ai/googles-new-agent-payments-protocol-ap2-allows-ai-agents-to-complete""><u>Agent Pay Protocol</u></a> (AP2) in collaboration with American Express, Mastercard, PayPal, Salesforce and ServiceNow. Visa followed soon after with TAP, which connects to the Visa Intelligent Commerce platform. </p><p>“The foundation is now in place through this collaboration, but successful agentic commerce requires thoughtful design that considers the specific needs of industry, users and existing systems while leveraging the standardized infrastructure and blueprints now available,” Mullins said. </p>",AI | VentureBeat,https://venturebeat.com/category/ai/feed/,AI,"OpenAI, Google, Amazon",100,True
Hybrid cloud security must be rebuilt for an AI war it was never designed to fight,https://venturebeat.com/security/hybrid-cloud-security-reinvented-ai-era,2025-11-30T16:00:00,louiswcolumbus@gmail.com (Louis Columbus),"<p>Hybrid cloud security was built before the current era of automated, machine-based cyberattacks that take just milliseconds to execute and minutes to deliver devastating impacts to infrastructure. </p><p>The architectures and tech stacks every enterprise depends on, from batch-based detection to siloed tools to 15-minute response windows, stood a better chance of defending against attackers moving at human speed. But in a weaponized AI world, those approaches to analyzing threat data don&#x27;t make sense. </p><p>The latest survey numbers tell the story. More than half (55%) of organizations suffered cloud breaches in the past year. That’s a 17-point spike, according to <a href=""https://www.gigamon.com/campaigns/hybrid-cloud-security-survey.html"">Gigamon&#x27;s 2025 Hybrid Cloud Security Survey</a>. Nearly half of the enterprises polled said their security tools missed the attack entirely. While <a href=""https://www.fortinet.com/blog/business-and-technology/navigating-todays-cloud-security-challenges"">82% of enterprises</a> now run hybrid or multi-cloud environments, only 36% express confidence in detecting threats in real time, per Fortinet&#x27;s 2025 State of Cloud Security Report.</p><p>Adversaries aren’t wasting any time weaponizing AI to target hybrid cloud vulnerabilities. Organizations now face <a href=""https://blog.checkpoint.com/research/q1-2025-global-cyber-attack-report-from-check-point-software-an-almost-50-surge-in-cyber-threats-worldwide-with-a-rise-of-126-in-ransomware-attacks/"">1,925 cyberattacks weekly</a>. That’s an increase of 47% in a year. Further, ransomware surged 126% in the first quarter of 2025 alone. The visibility gaps everyone talks about in hybrid environments is where breaches originate. The bottom line is that the security architectures designed for the pre-AI era can&#x27;t keep pace.</p><p>But the industry is finally beginning to respond. <a href=""https://www.crowdstrike.com/en-us/"">CrowdStrike</a>, for its part, is providing one vision of cybersecurity reinvention. Today at <a href=""https://reinvent.awsevents.com/"">AWS re:Invent</a>, the company is rolling out <a href=""https://www.crowdstrike.com/en-us/press-releases/crowdstrike-stops-cloud-attacks-with-real-time-cdr-innovations/"">real-time Cloud Detection and Response</a>, a platform designed to compress 15-minute response windows down to seconds. </p><p>But the bigger story is why the entire approach to hybrid cloud security must change, and what that means for CISOs planning their 2026 strategies.</p><h2>Why the old model for hybrid cloud security is failing</h2><p>Initially, hybrid cloud promised the best of both worlds. Every organization could have public cloud agility with on-prem control. The security model that took shape reflected the best practices at the time. The trouble is that those best practices are now introducing vulnerabilities.</p><p>How bad is it? The majority of security teams struggle to keep up with the threats and workloads. According to recent research: </p><ul><li><p><a href=""https://www.gigamon.com/campaigns/hybrid-cloud-security-survey.html"">91% of security leaders admit to making security compromises</a> in their hybrid cloud environments, often trading visibility for speed, accepting siloed tools, and working with degraded data quality.</p></li><li><p><a href=""https://www.fortinet.com/blog/business-and-technology/navigating-todays-cloud-security-challenges"">76% report a shortage of cloud security expertise</a>, limiting their ability to deploy and manage comprehensive solutions.</p></li><li><p><a href=""https://www.checkpoint.com/cyber-hub/cloud-security/what-is-cloud-security/top-cloud-security-challenges-2025/"">Only 17% of organizations can see attackers moving laterally</a> inside their network. That’s one of several blind spots that attackers capitalize on to exploit dwell times to the fullest, install ransomware, do reconnaissance, and lurk until the time is right to launch an attack.</p></li><li><p><a href=""https://www.gigamon.com/campaigns/hybrid-cloud-security-survey.html"">70% now view the public cloud as the riskiest environment</a> in their infrastructure, and half are considering moving workloads back on-prem.</p></li></ul><p>&quot;You can&#x27;t secure what you can&#x27;t see,&quot; <a href=""https://thecyberexpress.com/mandy-andress-complex-cybersecurity-challenges/"">says</a> Mandy Andress, CISO at <a href=""https://www.elastic.co/"">Elastic</a>. &quot;That&#x27;s the heart of the two big challenges we see as security practitioners: The complexity and sprawl of an organization&#x27;s infrastructure, coupled with the rapid pace of technological change.&quot;</p><p>CrowdStrike&#x27;s Zaitsev diagnosed the root cause: &quot;Everyone assumed this was a one-way trip, lift and shift everything to the cloud. That&#x27;s not what happened. We&#x27;re seeing companies pull workloads back on-prem when the economics make sense. The reality? Everyone&#x27;s going to be hybrid. Five years from now. Ten years. Maybe forever. Security has to deal with that.&quot;</p><h2>Weaponized AI is changing the threat calculus fast</h2><p>The weaponized AI era isn&#x27;t just accelerating attacks. It’s breaking the fundamental assumptions on which hybrid cloud security was built. The window between patch release and weaponized exploit collapsed from weeks to hours. The majority of adversaries aren&#x27;t typing commands anymore; they&#x27;re automating machine-based campaigns that orchestrate agentic AI at a scale and speed that current hybrid cloud tools and human SOC teams can&#x27;t keep up with.</p><p>Zaitsev shared threat data from CrowdStrike&#x27;s mid-year hunting report, which found that cloud intrusions spiked 136% in a year, with roughly 40% of all cloud actor activity coming from Chinese nexus adversaries. This illustrates how quickly the threat landscape can change, and why hybrid cloud security needs to be reinvented for the AI era now.</p><p>Mike Riemer, SVP and field CISO at <a href=""https://www.ivanti.com/"">Ivanti</a>, has witnessed the timeline collapse. Threat actors now reverse-engineer patches within 72 hours using AI assistance. If enterprises don&#x27;t patch within that time frame, &quot;they&#x27;re open to exploit,&quot; Riemer <a href=""https://venturebeat.com/security/weaponized-ai-can-dismantle-patches-in-72-hours-but-ivantis-kernel-defense"">told VentureBeat</a>. &quot;That&#x27;s the new reality.&quot;</p><p>Using previous-generation tools in the current cloud control plane is a dangerous bet. All it takes is a single compromised virtual machine (VM) that no one knows exists. Compromise the control plane, including the APIs that manage cloud resources, and they’ve got keys to spin up, modify or delete thousands of assets across a company’s hybrid environment.</p><p>The seams between hybrid cloud environments are attack highways where millisecond-long attacks seldom leave any digital exhaust or traces. Many organizations never see weaponized AI attacks coming.  </p><p>VentureBeat hears that the worst hybrid cloud attacks can only be diagnosed long after the fact, when forensics and analysis are finally completed. Attackers and adversaries are that good at covering their tracks, often relying on living-off-the-land (LotL) tools to evade detection for months, even years in extreme cases. </p><p>&quot;Enterprises training AI models are concentrating sensitive data in cloud environments, which is gold for adversaries,&quot; CrowdStrike&#x27;s Zaitsev said. &quot;Attackers are using agentic AI to run their campaigns. The traditional SOC workflow — see the alert, triage, investigate for 15 or 20 minutes, take action an hour or a day later —is completely insufficient. You&#x27;re bringing a knife to a gunfight.&quot;</p><h2>The human toll of relying on outdated architecture</h2><p>The human toll of the hybrid cloud crisis shows up in SOC metrics and burnout. The <a href=""https://thehackernews.com/2025/09/the-state-of-ai-in-soc-2025-insights.html"">AI SOC Market Landscape 2025 report</a> found that the average security operations center processes 960 alerts daily. Each takes roughly 70 minutes to investigate properly. Assuming standard SOC staffing levels, there aren&#x27;t enough hours in the day to get to all those alerts. </p><p>Futher, at least 40% of alerts, on average, never get touched. The human cost is staggering. A <a href=""https://www.darkreading.com/threat-intelligence/more-than-70-of-soc-analysts-experiencing-burnout"">Tines survey of SOC analysts</a> found that 71% are experiencing burnout. Two-thirds say manual grunt work consumes more than half of SOC workers&#x27; day. The same percentage are eyeing the exit from their jobs, and, in many extreme cases as some confide to VentureBeat, the industry.</p><p>Hybrid environments make everything more complicated. Enterprises have different tools for AWS, Azure and on-prem architectures. They have different consoles; often different teams. As for alert correlation across environments? It&#x27;s manual and often delegated to the most senior SOC team members — if it happens at all. </p><h2>Batch-based detection can&#x27;t survive the weaponized AI era</h2><p>Here&#x27;s what most legacy vendors of hybrid cloud security tools won&#x27;t openly admit: Cloud security tools are fundamentally flawed and not designed for real-time defense. The majority are batch-based, collecting logs every five, ten or fifteen minutes, processing them through correlation engines, then generating alerts. In a world where adversaries are increasingly executing machine-based attacks in milliseconds, a 15-minute detection delay isn&#x27;t just a minor setback; it&#x27;s the difference between stopping an attack and having to investigate a breach.</p><p>As adversaries weaponize AI to accelerate cloud attacks and move laterally across systems, traditional cloud detection and response (CDR) tools relying on log batch processing are too slow to keep up. These systems can take 15 minutes or more to surface a single detection.</p><p>CrowdStrike&#x27;s Zaitsev didn&#x27;t hedge. Before the company&#x27;s new tools released today, there was no such thing as real-time cloud detection and prevention, he claimed. &quot;Everyone else is batch-based. Suck down logs every five or 10 minutes, wait for data, import it, correlate it. We&#x27;ve seen competitors take 10 to 15 minutes minimum. That&#x27;s not detection—that&#x27;s archaeology.&quot;</p><p>He continued: &quot;It&#x27;s carrier pigeon versus 5G. The gap between 15 minutes and 15 seconds isn&#x27;t just about alert quality. It&#x27;s the difference between getting a notification that something has already happened; now you&#x27;re doing cleanup, versus actually stopping the attack before the adversary achieves anything. One is incident response. The other is prevention.&quot;</p><h2>Reinventing hybrid cloud security must begin with speed</h2><p>CrowdStrike&#x27;s new real-time Cloud Detection and Response, part of Falcon Cloud Security&#x27;s unified cloud-native application protection platform (CNAPP), is intended to secure every layer of hybrid cloud risk. It is built on three key innovations:</p><ul><li><p><b>Real-time detection engine: </b>Built on event streaming technology pioneered and battle-tested by Falcon Adversary OverWatch, this engine analyzes cloud logs as they stream in. It then applies detections to eliminate latency and false positives.</p></li><li><p><b>New cloud-specific indicators of attack out of the box: </b>AI and machine learning (ML) correlate what&#x27;s happening in real time against cloud asset and identity data. That&#x27;s how the system catches stealthy moves like privilege escalation and CloudShell abuse before attackers can capitalize on them.</p></li><li><p><b>Automated cloud response actions and workflows: </b>There&#x27;s a gap in traditional cloud security. Cloud workload protection (CWP) simply stops at the workload. Cloud security posture management (CSPM) shows what could go wrong. But neither protects the control plane at runtime. New workflows built on Falcon Fusion SOAR close that gap, triggering instantly to disrupt adversaries before SOC teams can intervene.</p></li></ul><p>CrowdStrike&#x27;s Cloud Detection and Response integrates with <a href=""https://aws.amazon.com/pm/eventbridge/"">AWS EventBridge</a>, Amazon&#x27;s real-time serverless event streaming service. Instead of polling for logs on a schedule, the system taps directly into the event stream as things happen. </p><p>&quot;Anything that calls itself CNAPP that doesn&#x27;t have real-time cloud detection and response is now obsolete,&quot; CrowdStrike CTO Elia Zaitsev said in an exclusive interview with VentureBeat. </p><p>By contrast, EventBridge provides a us asynchronous, microservice-based, just-in-time event processing. &quot;We&#x27;re not waiting five minutes for a bucket of data,&quot; he said. </p><p>But tapping into it is only half the problem. &quot;Can you actually keep up with that firehose? Can you process it fast enough to matter?&quot; Zaitsev asked rhetorically. CrowdStrike claims it can handle 60 million events per second. &quot;This isn&#x27;t duct tape and a demo.&quot;</p><p>The underlying streaming technology isn&#x27;t new to CrowdStrike. Falcon Adversary OverWatch has been running stream processing for 15 years to hunt across CrowdStrike&#x27;s customer base, processing logs in real time rather than waiting for batch cycles to complete.</p><p>The platform integrates Charlotte AI for automated triage, providing <a href=""https://venturebeat.com/security/crowdstrikes-ai-slashes-soc-workloads-over-40-hours-a-week"">98% accuracy</a> matching expert managed detection and response (MDR) analysts, cutting 40-plus hours of manual work weekly. When the system detects a control plane compromise, it doesn&#x27;t wait for human approval. It revokes tokens, kills sessions, boots the attacker and nukes malicious CloudFormation templates, all before the adversary can execute.</p><h2>What this means for the CNAPP market</h2><p><a href=""https://softwarestrategiesblog.com/2025/01/02/top-10-fastest-growing-segments-from-gartners-latest-information-security-forecast-q4-2024/"">Cloud security is the fastest-growing segment</a> in Gartner&#x27;s latest forecast, expanding at a 25.9% CAGR through 2028. Precedence Research projects the market will grow from <a href=""https://www.precedenceresearch.com/cloud-security-market"">$36 billion in 2024 to $121 billion by 2034</a>. And it&#x27;s crowded: Palo Alto Networks, Wiz (now absorbed into <a href=""https://venturebeat.com/ai/googles-32b-wiz-bet-ai-driven-cnapp-will-finally-eliminate-devsecops-bottlenecks"">Google via a $32 billion acquisition</a>), Microsoft, Orca, SentinelOne (to name a few). </p><p>CrowdStrike already had a seat at the table as a Leader in the 2025 IDC MarketScape for CNAPP for the third consecutive year. Gartner predicts that by 2029, <a href=""https://www.upwind.io/feed/2025-gartner-market-guide-for-cloud-native-application-protection-platforms-5-takeaways-that-we-believe-matter"">40% of enterprises that successfully implement zero trust</a> in cloud environments will rely on CNAPP platforms due to their visibility and control.</p><p>But Zaitsev is making a bigger claim, stating that today&#x27;s announcement redefines what &quot;complete&quot; means for CNAPP in hybrid environments. &quot;CSPM isn&#x27;t going away. Cloud workload protection isn&#x27;t going away. What becomes obsolete is calling something a CNAPP when it lacks real-time cloud detection and response. You&#x27;re missing the safety net, the thing that catches what gets through proactive defenses. And in hybrid, something always gets through.&quot;</p><p>The unified platform angle matters specifically for hybrid,&quot; he said. &quot;Adversaries deliberately hop between environments because they know defenders run different tools, often different teams, for cloud versus on-prem versus identity. Jumping domains is how you shake your tail. Attackers know most organizations can&#x27;t follow them across the seams. With us, they can&#x27;t do that anymore.&quot;</p><h2>Building hybrid security for the AI era</h2><p>Reinventing hybrid cloud security won&#x27;t happen overnight. Here&#x27;s where CISOs should focus:</p><ul><li><p><b>Map your hybrid visibility gaps: </b>Every cloud workload, every on-prem system, every identity traversing between them. If 82% of breaches trace to blind spots, know where yours are before attackers find them.</p></li><li><p><b>Pressure vendors on detection latency: </b>Ask challenging questions about architecture. If they&#x27;re running batch-based processing, understand what a 15-minute window means when adversaries move in seconds.</p></li><li><p><b>Deploy AI triage now: </b>With 40% of alerts going uninvestigated and 71% of analysts burned out, automation isn&#x27;t a roadmap item; it’s a must-have for a successful deterrence strategy. Look for measurable accuracy rates and real-time savings.</p></li><li><p><b>Compress patch cycles to 72 hours: </b>AI-assisted reverse engineering has collapsed the exploit window. Monthly patch cycles don&#x27;t cut it anymore.</p></li><li><p><b>Architect for permanent hybrid. </b>Stop waiting for cloud migration to simplify security. It won&#x27;t. Design for complexity as the baseline, not a temporary state. The 54% of enterprises running hybrid models today will still be hybrid tomorrow.</p></li></ul><h2>The bottom line</h2><p>Hybrid cloud security must be reinvented for the AI era. Previous-generation hybrid cloud security solutions are quickly being eclipsed by weaponized AI attacks, often launched as machine-on-machine intrusion attempts. The evidence is clear: 55% breach rates, 91% of security leaders making compromises they know are dangerous and AI-accelerated attacks that move faster than batch-based detection can respond. Architectures designed for human-speed threats can&#x27;t protect against machine-speed adversaries.</p><p>&quot;Modern cybersecurity is about differentiating between acceptable and unacceptable risk,&quot; says <a href=""https://www.gigamon.com/company/news-and-events/newsroom/survey-reveals-ciso-priorities-for-2025.html"">Chaim Mazal</a>, CSO at Gigamon. &quot;Our research shows where CISOs are drawing that line, highlighting the critical importance of visibility into all data-in-motion to secure complex hybrid cloud infrastructure against today&#x27;s emerging threats. It&#x27;s clear that current approaches aren&#x27;t keeping pace, which is why CISOs must reevaluate tool stacks and reprioritize investments and resources to more confidently secure their infrastructure.&quot;</p><p>VentureBeat will be tracking which approaches to hybrid cloud reinvention actually deliver, and which don&#x27;t, in the months ahead.</p>",AI | VentureBeat,https://venturebeat.com/category/ai/feed/,"Security, AI","Google, Microsoft, Amazon",100,True
OpenAI and NORAD team up to bring new magic to “NORAD Tracks Santa”,https://openai.com/index/norad-holiday-collaboration,2025-12-01T06:00:00,N/A,"OpenAI and NORAD are bringing new magic to “NORAD Tracks Santa” with three ChatGPT holiday tools that let families create festive elves, toy coloring pages, and custom Christmas stories.",OpenAI News,https://openai.com/blog/rss.xml,N/A,OpenAI,90,True
China’s DeepSeek V3.2 AI model achieves frontier performance on a fraction of the computing budget,https://www.artificialintelligence-news.com/news/deepseek-v3-2-matches-gpt-5-lower-training-costs/,2025-12-02T10:00:00,Dashveenjit Kaur,"<p>While tech giants pour billions into computational power to train frontier AI models, China&#8217;s DeepSeek has achieved comparable results by working smarter, not harder. The DeepSeek V3.2 AI model matches OpenAI&#8217;s GPT-5 in reasoning benchmarks despite using &#8216;fewer total training FLOPs&#8217; – a breakthrough that could reshape how the industry thinks about building advanced artificial [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/deepseek-v3-2-matches-gpt-5-lower-training-costs/"">China&#8217;s DeepSeek V3.2 AI model achieves frontier performance on a fraction of the computing budget</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://artificialintelligence-news.com/feed/,"AI Business Strategy, AI Market Trends, Deep Dives, Infrastructure & Hardware, ai benchmarking, china, deepseek, inference, reasoning",OpenAI,80,True
Edge AI inside the human body: Cochlear’s machine learning implant breakthrough,https://www.artificialintelligence-news.com/news/edge-ai-medical-devices-cochlear-implants/,2025-11-27T09:00:00,Dashveenjit Kaur,"<p>The next frontier for edge AI medical devices isn&#8217;t wearables or bedside monitors—it&#8217;s inside the human body itself. Cochlear&#8217;s newly launched&#160;Nucleus Nexa System&#160;represents the first cochlear implant capable of running machine learning algorithms while managing extreme power constraints, storing&#160;personalised data on-device, and receiving over-the-air firmware updates to improve its AI models over time. For AI [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/edge-ai-medical-devices-cochlear-implants/"">Edge AI inside the human body: Cochlear&#8217;s machine learning implant breakthrough</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://artificialintelligence-news.com/feed/,"AI and Us, AI in Action, Artificial Intelligence, Deep Dives, Healthcare & Wellness AI, How It Works, Human-AI Relationships, Interviews, ai, artificial intelligence, society",N/A,80,True
Adversarial learning breakthrough enables real-time AI security,https://www.artificialintelligence-news.com/news/adversarial-learning-breakthrough-real-time-ai-security/,2025-11-25T14:12:05,Ryan Daws,"<p>The ability to execute adversarial learning for real-time AI security offers a decisive advantage over static defence mechanisms. The emergence of AI-driven attacks – utilising reinforcement learning (RL) and Large Language Model (LLM) capabilities – has created a class of &#8220;vibe hacking&#8221; and adaptive threats that mutate faster than human teams can respond. This represents [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/adversarial-learning-breakthrough-real-time-ai-security/"">Adversarial learning breakthrough enables real-time AI security</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://artificialintelligence-news.com/feed/,"AI Business Strategy, AI in Action, Cybersecurity AI, Deep Dives, Features, How It Works, Inside AI, adversarial learning, ai, cybersecurity, infosec, security",N/A,80,True
China’s DeepSeek V3.2 AI model achieves frontier performance on a fraction of the computing budget,https://www.artificialintelligence-news.com/news/deepseek-v3-2-matches-gpt-5-lower-training-costs/,2025-12-02T10:00:00,Dashveenjit Kaur,"<p>While tech giants pour billions into computational power to train frontier AI models, China&#8217;s DeepSeek has achieved comparable results by working smarter, not harder. The DeepSeek V3.2 AI model matches OpenAI&#8217;s GPT-5 in reasoning benchmarks despite using &#8216;fewer total training FLOPs&#8217; – a breakthrough that could reshape how the industry thinks about building advanced artificial [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/deepseek-v3-2-matches-gpt-5-lower-training-costs/"">China&#8217;s DeepSeek V3.2 AI model achieves frontier performance on a fraction of the computing budget</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://www.artificialintelligence-news.com/feed/,"AI Business Strategy, AI Market Trends, Deep Dives, Infrastructure & Hardware, ai benchmarking, china, deepseek, inference, reasoning",OpenAI,80,True
Edge AI inside the human body: Cochlear’s machine learning implant breakthrough,https://www.artificialintelligence-news.com/news/edge-ai-medical-devices-cochlear-implants/,2025-11-27T09:00:00,Dashveenjit Kaur,"<p>The next frontier for edge AI medical devices isn&#8217;t wearables or bedside monitors—it&#8217;s inside the human body itself. Cochlear&#8217;s newly launched&#160;Nucleus Nexa System&#160;represents the first cochlear implant capable of running machine learning algorithms while managing extreme power constraints, storing&#160;personalised data on-device, and receiving over-the-air firmware updates to improve its AI models over time. For AI [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/edge-ai-medical-devices-cochlear-implants/"">Edge AI inside the human body: Cochlear&#8217;s machine learning implant breakthrough</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://www.artificialintelligence-news.com/feed/,"AI and Us, AI in Action, Artificial Intelligence, Deep Dives, Healthcare & Wellness AI, How It Works, Human-AI Relationships, Interviews, ai, artificial intelligence, society",N/A,80,True
Adversarial learning breakthrough enables real-time AI security,https://www.artificialintelligence-news.com/news/adversarial-learning-breakthrough-real-time-ai-security/,2025-11-25T14:12:05,Ryan Daws,"<p>The ability to execute adversarial learning for real-time AI security offers a decisive advantage over static defence mechanisms. The emergence of AI-driven attacks – utilising reinforcement learning (RL) and Large Language Model (LLM) capabilities – has created a class of &#8220;vibe hacking&#8221; and adaptive threats that mutate faster than human teams can respond. This represents [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/adversarial-learning-breakthrough-real-time-ai-security/"">Adversarial learning breakthrough enables real-time AI security</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://www.artificialintelligence-news.com/feed/,"AI Business Strategy, AI in Action, Cybersecurity AI, Deep Dives, Features, How It Works, Inside AI, adversarial learning, ai, cybersecurity, infosec, security",N/A,80,True
The Journey of a Token: What Really Happens Inside a Transformer,https://machinelearningmastery.com/the-journey-of-a-token-what-really-happens-inside-a-transformer/,2025-11-26T14:24:54,Iván Palomares Carrascosa,"Large language models (LLMs) are based on the transformer architecture, a complex deep neural network whose input is a sequence of token embeddings.",MachineLearningMastery.com,https://machinelearningmastery.com/feed/,N/A,N/A,80,True
GPU vs TPU: What’s the Difference?,https://www.analyticsvidhya.com/blog/2025/11/gpu-vs-tpu/,2025-11-28T11:34:14,Vipin Vashisth,"<p>AI and machine learning have pushed the demand for high-performance hardware, making the GPU-versus-TPU discussion more relevant than ever. GPUs, originally built for graphics, have grown into flexible processors for data analysis, scientific computing, and modern AI workloads. TPUs, built by Google as specialized ASICs for deep learning, focus on high-throughput tensor operations and have [&#8230;]</p>
<p>The post <a href=""https://www.analyticsvidhya.com/blog/2025/11/gpu-vs-tpu/"">GPU vs TPU: What&#8217;s the Difference?</a> appeared first on <a href=""https://www.analyticsvidhya.com"">Analytics Vidhya</a>.</p>",Analytics Vidhya,https://www.analyticsvidhya.com/feed/,"Artificial Intelligence, Machine Learning",Google,80,True
How OpenAI and Thrive are testing a new enterprise AI model,https://www.artificialintelligence-news.com/news/how-openai-and-thrive-are-testing-a-new-enterprise-ai-model/,2025-12-02T09:21:00,Muhammad Zulhusni,"<p>Thrive Holdings&#8217; push to modernise accounting and IT services is entering a new stage, as OpenAI prepares to take an ownership stake in the company and place its own specialists inside Thrive&#8217;s businesses. In doing so, OpenAI is testing an AI-driven model that pairs capital, sector expertise, and embedded technical teams. Thrive started its holding [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/how-openai-and-thrive-are-testing-a-new-enterprise-ai-model/"">How OpenAI and Thrive are testing a new enterprise AI model</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://artificialintelligence-news.com/feed/,"AI Business Strategy, World of Work, business processes, business strategy, chatgpt, data, enterprise",OpenAI,70,True
How background AI builds operational resilience & visible ROI,https://www.artificialintelligence-news.com/news/how-background-ai-builds-operational-resilience-visible-roi/,2025-11-28T10:51:13,Bazoom,"<p>If you asked most enterprise leaders which AI tools are delivering ROI, many would point to front-end chatbots or customer support automation. That&#8217;s the wrong door. The most value-generating AI systems today aren&#8217;t loud, customer-facing marvels. They&#8217;re tucked away in backend operations. They work silently, flagging irregularities in real-time, automating risk reviews, mapping data lineage, [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/how-background-ai-builds-operational-resilience-visible-roi/"">How background AI builds operational resilience &amp; visible ROI</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://artificialintelligence-news.com/feed/,"Artificial Intelligence, Sponsored Content",N/A,70,True
How OpenAI and Thrive are testing a new enterprise AI model,https://www.artificialintelligence-news.com/news/how-openai-and-thrive-are-testing-a-new-enterprise-ai-model/,2025-12-02T09:21:00,Muhammad Zulhusni,"<p>Thrive Holdings&#8217; push to modernise accounting and IT services is entering a new stage, as OpenAI prepares to take an ownership stake in the company and place its own specialists inside Thrive&#8217;s businesses. In doing so, OpenAI is testing an AI-driven model that pairs capital, sector expertise, and embedded technical teams. Thrive started its holding [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/how-openai-and-thrive-are-testing-a-new-enterprise-ai-model/"">How OpenAI and Thrive are testing a new enterprise AI model</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://www.artificialintelligence-news.com/feed/,"AI Business Strategy, World of Work, business processes, business strategy, chatgpt, data, enterprise",OpenAI,70,True
How background AI builds operational resilience & visible ROI,https://www.artificialintelligence-news.com/news/how-background-ai-builds-operational-resilience-visible-roi/,2025-11-28T10:51:13,Bazoom,"<p>If you asked most enterprise leaders which AI tools are delivering ROI, many would point to front-end chatbots or customer support automation. That&#8217;s the wrong door. The most value-generating AI systems today aren&#8217;t loud, customer-facing marvels. They&#8217;re tucked away in backend operations. They work silently, flagging irregularities in real-time, automating risk reviews, mapping data lineage, [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/how-background-ai-builds-operational-resilience-visible-roi/"">How background AI builds operational resilience &amp; visible ROI</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://www.artificialintelligence-news.com/feed/,"Artificial Intelligence, Sponsored Content",N/A,70,True
Prompt Compression for LLM Generation Optimization and Cost Reduction,https://machinelearningmastery.com/prompt-compression-for-llm-generation-optimization-and-cost-reduction/,2025-12-01T14:08:17,Iván Palomares Carrascosa,"Large language models (LLMs) are mainly trained to generate text responses to user queries or prompts, with complex reasoning under the hood that not only involves language generation by predicting each next token in the output sequence, but also entails a deep understanding of the linguistic patterns surrounding the user input text.",MachineLearningMastery.com,https://machinelearningmastery.com/feed/,N/A,N/A,70,True
The Machine Learning and Deep Learning “Advent Calendar” Series: The Blueprint,https://towardsdatascience.com/machine-learning-and-deep-learning-in-excel-advent-calendar-announcement/,2025-11-30T15:00:00,angela shi,"<p>Opening the black box of ML models, step by step, directly in Excel</p>
<p>The post <a href=""https://towardsdatascience.com/machine-learning-and-deep-learning-in-excel-advent-calendar-announcement/"">The Machine Learning and Deep Learning “Advent Calendar” Series: The Blueprint</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Machine Learning, Algorithms, Artificial Intelligence, Data Science, Deep Learning",N/A,70,True
Deep Agents Tutorial: Create Advanced AI Agents with LangGraph and Web Search Tools,https://www.analyticsvidhya.com/blog/2025/11/langchains-deep-agent-guide/,2025-11-30T11:23:47,Mounish V,"<p>Imagine an AI that doesn’t just answer your questions, but thinks ahead, breaks tasks down, creates its own TODOs, and even spawns sub-agents to get the work done. That’s the promise of Deep Agents. AI Agents already take the capabilities of LLMs a notch higher, and today we’ll look at Deep Agents to see how [&#8230;]</p>
<p>The post <a href=""https://www.analyticsvidhya.com/blog/2025/11/langchains-deep-agent-guide/"">Deep Agents Tutorial: Create Advanced AI Agents with LangGraph and Web Search Tools </a> appeared first on <a href=""https://www.analyticsvidhya.com"">Analytics Vidhya</a>.</p>",Analytics Vidhya,https://www.analyticsvidhya.com/feed/,"Beginner, Generative AI, LLMs",N/A,70,True
Expanding data residency access to business customers worldwide,https://openai.com/index/expanding-data-residency-access-to-business-customers-worldwide,2025-11-25T22:00:00,N/A,"OpenAI expands data residency for ChatGPT Enterprise, ChatGPT Edu, and the API Platform, enabling eligible customers to store data at rest in-region.",OpenAI News,https://openai.com/blog/rss.xml,N/A,OpenAI,60,True
How the MCP spec update boosts security as infrastructure scales,https://www.artificialintelligence-news.com/news/how-the-mcp-spec-update-boosts-security-as-infrastructure-scales/,2025-11-27T13:34:34,Ryan Daws,"<p>The latest MCP spec update fortifies enterprise infrastructure with tighter security, moving AI agents from pilot to production. Marking its first year, the Anthropic-created open-source project released a revised spec this week aimed at the operational headaches keeping generative AI agents stuck in pilot mode. Backed by Amazon Web Services (AWS), Microsoft, and Google Cloud, [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/how-the-mcp-spec-update-boosts-security-as-infrastructure-scales/"">How the MCP spec update boosts security as infrastructure scales</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://artificialintelligence-news.com/feed/,"Deep Dives, Features, Governance, Regulation & Policy, How It Works, Inside AI, agents, ai, cybersecurity, enterprise, infosec, infrastructure, mcp, security","Anthropic, Google, Microsoft, Amazon",50,True
Inside Mirakl’s Agent Commerce Vision,https://openai.com/index/mirakl,2025-12-01T22:00:00,N/A,"Mirakl is redefining commerce through AI agents and ChatGPT Enterprise—achieving faster documentation, smarter customer support, and building toward agent-native commerce with Mirakl Nexus.",OpenAI News,https://openai.com/blog/rss.xml,N/A,N/A,50,True
How the MCP spec update boosts security as infrastructure scales,https://www.artificialintelligence-news.com/news/how-the-mcp-spec-update-boosts-security-as-infrastructure-scales/,2025-11-27T13:34:34,Ryan Daws,"<p>The latest MCP spec update fortifies enterprise infrastructure with tighter security, moving AI agents from pilot to production. Marking its first year, the Anthropic-created open-source project released a revised spec this week aimed at the operational headaches keeping generative AI agents stuck in pilot mode. Backed by Amazon Web Services (AWS), Microsoft, and Google Cloud, [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/how-the-mcp-spec-update-boosts-security-as-infrastructure-scales/"">How the MCP spec update boosts security as infrastructure scales</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://www.artificialintelligence-news.com/feed/,"Deep Dives, Features, Governance, Regulation & Policy, How It Works, Inside AI, agents, ai, cybersecurity, enterprise, infosec, infrastructure, mcp, security","Anthropic, Google, Microsoft, Amazon",50,True
"Apple just named a new AI chief with Google and Microsoft expertise, as John Giannandrea steps down",https://techcrunch.com/2025/12/01/apple-just-named-a-new-ai-chief-with-google-and-microsoft-expertise-as-john-giannandrea-steps-down/,2025-12-02T01:34:46,Connie Loizos,"His replacement is Amar Subramanya, a highly regarded Microsoft executive who spent 16 years at Google, most recently leading engineering for the Gemini Assistant. It's a savvy hire, given that Subramanya knows the competition intimately.",AI News & Artificial Intelligence | TechCrunch,https://techcrunch.com/category/artificial-intelligence/feed/,"AI, Apple, Apple Intelligence, Google, John Giannandrea","Google, Microsoft, Apple",40,True
Nvidia announces new open AI models and tools for autonomous driving research,https://techcrunch.com/2025/12/01/nvidia-announces-new-open-ai-models-and-tools-for-autonomous-driving-research/,2025-12-01T21:00:22,Rebecca Szkutak,Nvidia continues its push into physical AI with the release of a new reasoning world model and other tools for physical AI.,AI News & Artificial Intelligence | TechCrunch,https://techcrunch.com/category/artificial-intelligence/feed/,"AI, Hardware, Robotics, Transportation, nvidia, autonomous driving, Jensen Huang, physical ai",NVIDIA,40,True
OpenAI’s investment into Thrive Holdings is its latest circular deal,https://techcrunch.com/2025/12/01/openais-investment-into-thrive-holdings-is-its-latest-circular-deal/,2025-12-01T16:58:17,Rebecca Bellan,"Analysts will be watching to see if Thrive-owned firms actually succeed in building long-term profitable businesses using OpenAI’s tech, or if the result is really just pumped up valuations based on speculative market potential.",AI News & Artificial Intelligence | TechCrunch,https://techcrunch.com/category/artificial-intelligence/feed/,"AI, Fundraising, Venture, AI bubble, circular deals, In Brief, OpenAI, Thrive Capital, thrive holdings",OpenAI,40,True
Amazon’s AI chatbot Rufus drove sales on Black Friday,https://techcrunch.com/2025/12/01/amazons-ai-chatbot-rufus-drove-sales-on-black-friday/,2025-12-01T16:25:24,Sarah Perez,"On Black Friday, Amazon sessions that resulted in a sale were up 100% in the U.S. when the AI chatbot Rufus was used. They only increased by 20% when Rufus wasn't used.",AI News & Artificial Intelligence | TechCrunch,https://techcrunch.com/category/artificial-intelligence/feed/,"AI, Commerce, Amazon, black friday, e-commerce, online shopping, AI chatbot",Amazon,40,True
‘Avatar’ director James Cameron says generative AI is ‘horrifying’,https://techcrunch.com/2025/11/30/avatar-director-james-cameron-says-generative-ai-is-horrifying/,2025-11-30T22:53:15,Anthony Ha,"James Cameron’s movies are often at the cutting edge of visual effects technology, but that doesn't make him a fan of generative AI.",AI News & Artificial Intelligence | TechCrunch,https://techcrunch.com/category/artificial-intelligence/feed/,"AI, Media & Entertainment, Avatar, James Cameron, In Brief",N/A,40,True
ChatGPT launched three years ago today,https://techcrunch.com/2025/11/30/chatgpt-launched-three-years-ago-today/,2025-11-30T20:14:09,Anthony Ha,It’s no hyperbole to suggest that ChatGPT subsequently transformed the worlds of business and tech.,AI News & Artificial Intelligence | TechCrunch,https://techcrunch.com/category/artificial-intelligence/feed/,"AI, Startups, ChatGPT, OpenAI",N/A,40,True
"No, you can’t get your AI to ‘admit’ to being sexist, but it probably is anyway",https://techcrunch.com/2025/11/29/no-you-cant-get-your-ai-to-admit-to-being-sexist-but-it-probably-is/,2025-11-29T16:00:00,Dominic-Madori Davis,"Though LLMs might not use explicitly biased language, they may infer your demographic data and display implicit biases, researchers say.",AI News & Artificial Intelligence | TechCrunch,https://techcrunch.com/category/artificial-intelligence/feed/,"AI, Exclusive, OpenAI, AI chatbot, DEI, LLMs, ChatGPT",N/A,40,True
How OpenAI and Google see AI changing go-to-market strategies,https://techcrunch.com/2025/11/28/how-openai-and-google-see-ai-changing-go-to-market-strategies/,2025-11-28T16:00:00,Tim De Chant,AI is changing how investors and startups bring their products to market. Three experts offered their insights at TechCrunch Disrupt.,AI News & Artificial Intelligence | TechCrunch,https://techcrunch.com/category/artificial-intelligence/feed/,"Startups, AI, Google, TechCrunch Disrupt, google cloud, OpenAI, GTMfund, TechCrunch Disrupt 2025","OpenAI, Google",40,True
The race to regulate AI has sparked a federal vs. state showdown,https://techcrunch.com/2025/11/28/the-race-to-regulate-ai-has-sparked-a-federal-vs-state-showdown/,2025-11-28T15:00:00,Rebecca Bellan,"The fight over AI regulation isn't about the technology — it's about whether Washington or the states get to set the rules, and what happens to consumers caught in between.",AI News & Artificial Intelligence | TechCrunch,https://techcrunch.com/category/artificial-intelligence/feed/,"AI, Government & Policy, AI moratorium, AI policy, leading the future, ndaa",N/A,40,True
"Apple just named a new AI chief with Google and Microsoft expertise, as John Giannandrea steps down",https://techcrunch.com/2025/12/01/apple-just-named-a-new-ai-chief-with-google-and-microsoft-expertise-as-john-giannandrea-steps-down/,2025-12-02T01:34:46,Connie Loizos,"His replacement is Amar Subramanya, a highly regarded Microsoft executive who spent 16 years at Google, most recently leading engineering for the Gemini Assistant. It's a savvy hire, given that Subramanya knows the competition intimately.",TechCrunch,https://techcrunch.com/feed/,"AI, Apple, Apple Intelligence, Google, John Giannandrea","Google, Microsoft, Apple",40,True
Nvidia announces new open AI models and tools for autonomous driving research,https://techcrunch.com/2025/12/01/nvidia-announces-new-open-ai-models-and-tools-for-autonomous-driving-research/,2025-12-01T21:00:22,Rebecca Szkutak,Nvidia continues its push into physical AI with the release of a new reasoning world model and other tools for physical AI.,TechCrunch,https://techcrunch.com/feed/,"AI, Hardware, Robotics, Transportation, nvidia, autonomous driving, Jensen Huang, physical ai",NVIDIA,40,True
OpenAI’s investment into Thrive Holdings is its latest circular deal,https://techcrunch.com/2025/12/01/openais-investment-into-thrive-holdings-is-its-latest-circular-deal/,2025-12-01T16:58:17,Rebecca Bellan,"Analysts will be watching to see if Thrive-owned firms actually succeed in building long-term profitable businesses using OpenAI’s tech, or if the result is really just pumped up valuations based on speculative market potential.",TechCrunch,https://techcrunch.com/feed/,"AI, Fundraising, Venture, AI bubble, circular deals, In Brief, OpenAI, Thrive Capital, thrive holdings",OpenAI,40,True
Amazon’s AI chatbot Rufus drove sales on Black Friday,https://techcrunch.com/2025/12/01/amazons-ai-chatbot-rufus-drove-sales-on-black-friday/,2025-12-01T16:25:24,Sarah Perez,"On Black Friday, Amazon sessions that resulted in a sale were up 100% in the U.S. when the AI chatbot Rufus was used. They only increased by 20% when Rufus wasn't used.",TechCrunch,https://techcrunch.com/feed/,"AI, Commerce, Amazon, black friday, e-commerce, online shopping, AI chatbot",Amazon,40,True
The State of AI: Welcome to the economic singularity,https://www.technologyreview.com/2025/12/01/1127872/the-state-of-ai-welcome-to-the-economic-singularity/,2025-12-01T16:30:00,David Rotman and Richard Waters,"Welcome back to The State of AI, a new collaboration between the Financial Times and MIT Technology Review. Every Monday for the next two weeks, writers from both publications will debate one aspect of the generative AI revolution reshaping global power. This week, Richard Waters, FT columnist and former West Coast editor, talks with MIT&#8230;",Artificial intelligence – MIT Technology Review,https://www.technologyreview.com/topic/artificial-intelligence/feed,"Artificial intelligence, App, The Algorithm, The State of AI, Why It Matters",N/A,40,True
An AI model trained on prison phone calls now looks for planned crimes in those calls,https://www.technologyreview.com/2025/12/01/1128591/an-ai-model-trained-on-prison-phone-calls-is-now-being-used-to-surveil-inmates/,2025-12-01T10:30:00,James O'Donnell,"A US telecom company trained an AI model on years of inmates’ phone and video calls and is now piloting that model to scan their calls, texts, and emails in the hope of predicting and preventing crimes.&#160; Securus Technologies president Kevin Elder told MIT Technology Review that the company began building its AI tools in&#8230;",Artificial intelligence – MIT Technology Review,https://www.technologyreview.com/topic/artificial-intelligence/feed,"Artificial intelligence, App, artificial intelligence",N/A,40,True
AI business reality – what enterprise leaders need to know,https://www.artificialintelligence-news.com/news/ai-business-reality-what-enterprise-leaders-need-know/,2025-12-01T08:00:00,Dashveenjit Kaur,"<p>When JPMorgan Asset Management reported that AI spending accounted for two-thirds of US GDP growth in the first half of 2025, it wasn&#8217;t just a statistic – it was a signal. The conversation reached a turning point recently when OpenAI CEO Sam Altman, Amazon&#8217;s Jeff Bezos, and Goldman Sachs CEO David Solomon each acknowledged market [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/ai-business-reality-what-enterprise-leaders-need-know/"">AI business reality – what enterprise leaders need to know</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://artificialintelligence-news.com/feed/,"AI Business Strategy, AI Market Trends, Deep Dives, business strategy, digital transformation, investment, resource choices","OpenAI, Amazon",40,True
Manufacturing’s pivot: AI as a strategic driver,https://www.artificialintelligence-news.com/news/manufacturings-pivot-ai-as-a-strategic-driver/,2025-11-25T16:04:39,AI News,"<p>Manufacturers today are working against rising input costs, labour shortages, supply-chain fragility, and pressure to offer more customised products. AI is becoming an important part of a response to those pressures. When enterprise strategy depends on AI Most manufacturers seek to reduce cost while improving throughput and quality. AI supports these aims by predicting equipment [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/manufacturings-pivot-ai-as-a-strategic-driver/"">Manufacturing&#8217;s pivot: AI as a strategic driver</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://artificialintelligence-news.com/feed/,"AI Business Strategy, Manufacturing & Engineering AI, ai deployments, engineering, manufacturing, strategy",N/A,40,True
"Google, Nvidia, and OpenAI",https://stratechery.com/2025/google-nvidia-and-openai/,2025-12-01T15:18:42,N/A,"<a href=""https://news.ycombinator.com/item?id=46108437"">Comments</a>",Hacker News,https://news.ycombinator.com/rss,N/A,"OpenAI, Google, NVIDIA",40,True
Funding grants for new research into AI and mental health,https://openai.com/index/ai-mental-health-research-grants,2025-12-01T12:00:00,N/A,"OpenAI is awarding up to $2 million in grants for research at the intersection of AI and mental health. The program supports projects that study real-world risks, benefits, and applications to improve safety and well-being.",OpenAI News,https://openai.com/blog/rss.xml,N/A,OpenAI,40,True
Accenture and OpenAI accelerate enterprise AI success,https://openai.com/index/accenture-partnership,2025-12-01T05:00:00,N/A,Accenture and OpenAI are collaborating to help enterprises bring agentic AI capabilities into the core of their business and unlock new levels of growth.,OpenAI News,https://openai.com/blog/rss.xml,N/A,OpenAI,40,True
OpenAI takes an ownership stake in Thrive Holdings to accelerate enterprise AI adoption,https://openai.com/index/thrive-holdings,2025-12-01T05:00:00,N/A,"OpenAI takes an ownership stake in Thrive Holdings to accelerate enterprise AI adoption, embedding frontier research and engineering directly into accounting and IT services to boost speed, accuracy, and efficiency while creating a scalable model for industry-wide transformation.",OpenAI News,https://openai.com/blog/rss.xml,N/A,OpenAI,40,True
Mixpanel security incident: what OpenAI users need to know,https://openai.com/index/mixpanel-incident,2025-11-26T19:00:00,N/A,"OpenAI shares details about a Mixpanel security incident involving limited API analytics data. No API content, credentials, or payment details were exposed. Learn what happened and how we’re protecting users.",OpenAI News,https://openai.com/blog/rss.xml,N/A,OpenAI,40,True
AI business reality – what enterprise leaders need to know,https://www.artificialintelligence-news.com/news/ai-business-reality-what-enterprise-leaders-need-know/,2025-12-01T08:00:00,Dashveenjit Kaur,"<p>When JPMorgan Asset Management reported that AI spending accounted for two-thirds of US GDP growth in the first half of 2025, it wasn&#8217;t just a statistic – it was a signal. The conversation reached a turning point recently when OpenAI CEO Sam Altman, Amazon&#8217;s Jeff Bezos, and Goldman Sachs CEO David Solomon each acknowledged market [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/ai-business-reality-what-enterprise-leaders-need-know/"">AI business reality – what enterprise leaders need to know</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://www.artificialintelligence-news.com/feed/,"AI Business Strategy, AI Market Trends, Deep Dives, business strategy, digital transformation, investment, resource choices","OpenAI, Amazon",40,True
Manufacturing’s pivot: AI as a strategic driver,https://www.artificialintelligence-news.com/news/manufacturings-pivot-ai-as-a-strategic-driver/,2025-11-25T16:04:39,AI News,"<p>Manufacturers today are working against rising input costs, labour shortages, supply-chain fragility, and pressure to offer more customised products. AI is becoming an important part of a response to those pressures. When enterprise strategy depends on AI Most manufacturers seek to reduce cost while improving throughput and quality. AI supports these aims by predicting equipment [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/manufacturings-pivot-ai-as-a-strategic-driver/"">Manufacturing&#8217;s pivot: AI as a strategic driver</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://www.artificialintelligence-news.com/feed/,"AI Business Strategy, Manufacturing & Engineering AI, ai deployments, engineering, manufacturing, strategy",N/A,40,True
How to Speed-Up Training of Language Models,https://machinelearningmastery.com/how-to-speed-up-training-of-language-models/,2025-11-30T14:49:19,Adrian Tam,This article is divided into four parts; they are: • Optimizers for Training Language Models • Learning Rate Schedulers • Sequence Length Scheduling • Other Techniques to Help Training Deep Learning Models Adam has been the most popular optimizer for training deep learning models.,MachineLearningMastery.com,https://machinelearningmastery.com/feed/,N/A,N/A,40,True
Pretrain a BERT Model from Scratch,https://machinelearningmastery.com/pretrain-a-bert-model-from-scratch/,2025-11-26T05:30:06,Adrian Tam,"This article is divided into three parts; they are: • Creating a BERT Model the Easy Way • Creating a BERT Model from Scratch with PyTorch • Pre-training the BERT Model If your goal is to create a BERT model so that you can train it on your own data, using the Hugging Face `transformers` library is the easiest way to get started.",MachineLearningMastery.com,https://machinelearningmastery.com/feed/,N/A,Hugging Face,40,True
The Machine Learning Lessons I’ve Learned This Month,https://towardsdatascience.com/the-machine-learning-lessons-ive-learned-this-month-3/,2025-12-01T20:03:39,Pascal Janetzky,"<p>Christmas connections, Copilot's costs, careful (no-)choices</p>
<p>The post <a href=""https://towardsdatascience.com/the-machine-learning-lessons-ive-learned-this-month-3/"">The Machine Learning Lessons I’ve Learned This Month</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Machine Learning, AI coding assistants, Data Science, Github Copilot, Learning Rate",N/A,40,True
"Learning, Hacking, and Shipping ML",https://towardsdatascience.com/learning-hacking-and-shipping-ml/,2025-12-01T15:22:11,TDS Editors,"<p>Vyacheslav Efimov on AI hackathons, data science roadmaps, and how AI meaningfully changed day-to-day ML Engineer work</p>
<p>The post <a href=""https://towardsdatascience.com/learning-hacking-and-shipping-ml/"">Learning, Hacking, and Shipping ML</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Artificial Intelligence, Author Spotlights, Data Science, Machine Learning, Python",N/A,40,True
Your Next LLM Might Not Predict Tokens One-by-One,https://towardsdatascience.com/why-weve-been-optimizing-the-wrong-thing-in-llms-for-years/,2025-11-28T14:00:00,Moulik Gupta,"<p>The simple shift in training that unlocks foresight, faster inference, and better reasoning.</p>
<p>The post <a href=""https://towardsdatascience.com/why-weve-been-optimizing-the-wrong-thing-in-llms-for-years/"">Your Next LLM Might Not Predict Tokens One-by-One</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Large Language Models, Artificial Intelligence, Editors Pick, Llm, Next Word Prediction",N/A,40,True
"TDS Newsletter: November Must-Reads on GraphRAG, ML Projects, LLM-Powered Time-Series Analysis, and More",https://towardsdatascience.com/tds-newsletter-november-must-reads-on-graphrag-ml-projects-llm-powered-time-series-analysis-and-more/,2025-11-27T17:50:00,TDS Editors,"<p>Don't miss our most-read stories of the past month</p>
<p>The post <a href=""https://towardsdatascience.com/tds-newsletter-november-must-reads-on-graphrag-ml-projects-llm-powered-time-series-analysis-and-more/"">TDS Newsletter: November Must-Reads on GraphRAG, ML Projects, LLM-Powered Time-Series Analysis, and More</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"The Variable, Data Science, Machine Learning, Monthly Edition, Tds Features",N/A,40,True
How I Use AI to Convince Companies to Adopt Sustainability,https://towardsdatascience.com/how-i-use-ai-to-convince-companies-to-adopt-sustainability/,2025-11-26T12:00:00,Samir Saci,"<p>Discover how Claude can act as a Supply Chain Sustainability Analyst and guide companies toward greener, more efficient inventory management.</p>
<p>The post <a href=""https://towardsdatascience.com/how-i-use-ai-to-convince-companies-to-adopt-sustainability/"">How I Use AI to Convince Companies to Adopt Sustainability</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Large Language Models, Articial Intelligence, Editors Pick, Logistics, mcp, Supply Chain, Sustainability",N/A,40,True
The Generative AI Scientist Roadmap 2026,https://www.analyticsvidhya.com/blog/2025/12/generative-ai-scientist-roadmap/,2025-12-01T19:32:24,Aayush Tyagi,"<p>Some people want to “learn AI.” Others want to build the future. If you’re in the second category, bookmark this right now &#8211; because the Generative AI Scientist Roadmap 2026 isn’t another cute syllabus. It’s the no-nonsense, industry-level blueprint for turning you from “I know Python loops” into “I can architect agents that run companies.” [&#8230;]</p>
<p>The post <a href=""https://www.analyticsvidhya.com/blog/2025/12/generative-ai-scientist-roadmap/"">The Generative AI Scientist Roadmap 2026</a> appeared first on <a href=""https://www.analyticsvidhya.com"">Analytics Vidhya</a>.</p>",Analytics Vidhya,https://www.analyticsvidhya.com/feed/,"Beginner, Career, Generative AI, Interview Prep",N/A,40,True
How to Use KV Caching in LLMs?,https://www.analyticsvidhya.com/blog/2025/11/kv-caching-guide/,2025-11-27T07:04:04,Shaik Hamzah,"<p>LLMs have been a trending topic lately, but it&#8217;s always interesting to understand how these LLMs work behind the scenes. For those unaware, LLMs have been in development since 2017&#8217;s release of the famed research paper “Attention is all you need”. But these early transformer-based models had quite a few drawbacks due to heavy computation [&#8230;]</p>
<p>The post <a href=""https://www.analyticsvidhya.com/blog/2025/11/kv-caching-guide/"">How to Use KV Caching in LLMs?</a> appeared first on <a href=""https://www.analyticsvidhya.com"">Analytics Vidhya</a>.</p>",Analytics Vidhya,https://www.analyticsvidhya.com/feed/,"Intermediate, LLMs",N/A,40,True
One of Google’s biggest AI advantages is what it already knows about you,https://techcrunch.com/2025/12/01/one-of-googles-biggest-ai-advantages-is-what-it-already-knows-about-you/,2025-12-02T00:17:52,Sarah Perez,The promise is AI that's uniquely helpful because it knows you. But the risk is AI that feels more like surveillance than service.,AI News & Artificial Intelligence | TechCrunch,https://techcrunch.com/category/artificial-intelligence/feed/,"AI, Privacy, data privacy, gemini, Google, Google Search",Google,30,True
Construction workers are cashing in on the AI boom,https://techcrunch.com/2025/12/01/construction-workers-are-cashing-in-on-the-ai-boom/,2025-12-01T19:13:50,Connie Loizos,"""I pinch myself going to work every day,"" one 51-year-old says of his new supervisor role overseeing 200 workers at a data center site.",AI News & Artificial Intelligence | TechCrunch,https://techcrunch.com/category/artificial-intelligence/feed/,"AI, construction, data centers, In Brief",N/A,30,True
Black Forest Labs raises $300M at $3.25B valuation,https://techcrunch.com/2025/12/01/black-forest-labs-raises-300m-at-3-25b-valuation/,2025-12-01T14:08:13,Ram Iyer,"The round was co-led by Salesforce Ventures and Anjney Midha (AMP), and saw participation from a16z, NVIDIA, Northzone, Creandum, Earlybird VC, BroadLight Capital, General Catalyst, Temasek, Bain Capital Ventures, Air Street Capital, Visionaries Club, Canva and Figma Ventures.",AI News & Artificial Intelligence | TechCrunch,https://techcrunch.com/category/artificial-intelligence/feed/,"AI, Fundraising, a16z, AI image generation, bain ventures, black forest labs, Creandum, General Catalyst, In Brief, temasek",NVIDIA,30,True
Supabase CEO on the ‘painful’ decisions that built a $5B company,https://techcrunch.com/podcast/supabase-ceo-on-the-painful-decisions-that-built-a-5b-company/,2025-11-28T17:20:00,"Theresa Loconsolo, Julie Bort","Vibe coding has taken the tech industry by storm, and&#160;it&#8217;s&#160;not just the&#160;Lovables&#160;and&#160;Replits&#160;of the world that are&#160;winning. The startups building the infrastructure behind them are cashing in too.&#160; Supabase, the open source database platform that&#8217;s become the back end of choice for the vibe-coding world, raised $100 million at a $5 billion valuation just months after [&#8230;]",AI News & Artificial Intelligence | TechCrunch,https://techcrunch.com/category/artificial-intelligence/feed/,"Startups, AI, Equity podcast, Supabase, database services, ai infrastructure, vibe-coding",N/A,30,True
One of Google’s biggest AI advantages is what it already knows about you,https://techcrunch.com/2025/12/01/one-of-googles-biggest-ai-advantages-is-what-it-already-knows-about-you/,2025-12-02T00:17:52,Sarah Perez,The promise is AI that's uniquely helpful because it knows you. But the risk is AI that feels more like surveillance than service.,TechCrunch,https://techcrunch.com/feed/,"AI, Privacy, data privacy, gemini, Google, Google Search",Google,30,True
Zillow drops climate risk scores after agents complained of lost sales,https://techcrunch.com/2025/12/01/zillow-drops-climate-risk-scores-after-agents-complained-of-lost-sales/,2025-12-01T22:44:28,Tim De Chant,"The move is a loss for homebuyers, who through Zillow had ready access to a property's climate risk scores from First Street.",TechCrunch,https://techcrunch.com/feed/,"Climate, Real estate, climate risk modelling, floods, insurance, PropTech, real estate agents, wildfires, Zillow",N/A,30,True
Construction workers are cashing in on the AI boom,https://techcrunch.com/2025/12/01/construction-workers-are-cashing-in-on-the-ai-boom/,2025-12-01T19:13:50,Connie Loizos,"""I pinch myself going to work every day,"" one 51-year-old says of his new supervisor role overseeing 200 workers at a data center site.",TechCrunch,https://techcrunch.com/feed/,"AI, construction, data centers, In Brief",N/A,30,True
How AI PR startup Clipbook won Mark Cuban’s investment from a cold email,https://techcrunch.com/2025/12/01/how-ai-pr-startup-clipbook-won-mark-cubans-investment-from-a-cold-email/,2025-12-01T16:00:00,Julie Bort,Adam Joseph was shocked when Mark Cuban replied to his email with an inquisition full of questions.,TechCrunch,https://techcrunch.com/feed/,"Startups, TC, Venture, mark cuban, public relations, Sprinklr",N/A,30,True
Black Forest Labs raises $300M at $3.25B valuation,https://techcrunch.com/2025/12/01/black-forest-labs-raises-300m-at-3-25b-valuation/,2025-12-01T14:08:13,Ram Iyer,"The round was co-led by Salesforce Ventures and Anjney Midha (AMP), and saw participation from a16z, NVIDIA, Northzone, Creandum, Earlybird VC, BroadLight Capital, General Catalyst, Temasek, Bain Capital Ventures, Air Street Capital, Visionaries Club, Canva and Figma Ventures.",TechCrunch,https://techcrunch.com/feed/,"AI, Fundraising, a16z, AI image generation, bain ventures, black forest labs, Creandum, General Catalyst, In Brief, temasek",NVIDIA,30,True
The AI Hype Index: The people can’t get enough of AI slop,https://www.technologyreview.com/2025/11/26/1128353/the-ai-hype-index-the-people-cant-get-enough-of-ai-slop/,2025-11-26T10:00:00,The Editors,"Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry. Last year, the fantasy author Joanna Maciejewska went viral (if such a thing is still possible on X) with a post saying “I&#8230;",Artificial intelligence – MIT Technology Review,https://www.technologyreview.com/topic/artificial-intelligence/feed,"Artificial intelligence, AI, AI Hype Index, App",N/A,30,True
"HP plans to save millions by laying off thousands, ramping up AI use",https://arstechnica.com/information-technology/2025/11/hp-plans-to-save-millions-by-laying-off-thousands-ramping-up-ai-use/,2025-11-26T17:19:35,Scharon Harding,"Product development, internal operations among teams expected to be hit hardest.",Biz & IT – Ars Technica,https://feeds.arstechnica.com/arstechnica/technology-lab,"AI, Biz & IT, AI layoffs, HP, layoffs",N/A,30,True
Agentic AI autonomy grows in North American enterprises,https://www.artificialintelligence-news.com/news/agentic-ai-autonomy-grows-in-north-american-enterprises/,2025-12-01T15:53:22,Ryan Daws,"<p>North American enterprises are now actively deploying agentic AI systems intended to reason, adapt, and act with complete autonomy. Data from Digitate’s three-year global programme indicates that, while adoption is universal across the board, regional maturity paths are diverging. North American firms are scaling toward full autonomy, whereas their European counterparts are prioritising governance frameworks [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/agentic-ai-autonomy-grows-in-north-american-enterprises/"">Agentic AI autonomy grows in North American enterprises</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://artificialintelligence-news.com/feed/,"AI and Us, AI Business Strategy, AI Market Trends, Features, Governance, Regulation & Policy, Human-AI Relationships, Inside AI, Special Reports & Series, Trust, Bias & Fairness, World of Work, adoption, agentic ai, agents, automation, enterprise, operations, skills, strategy, trust, workforce",N/A,30,True
SAP outlines new approach to European AI and cloud sovereignty,https://www.artificialintelligence-news.com/news/sap-outlines-new-approach-to-european-ai-and-cloud-sovereignty/,2025-11-27T14:06:00,Muhammad Zulhusni,"<p>SAP is moving its sovereignty plans forward with EU AI Cloud, a setup meant to unify its efforts in the region under one approach. The goal is to give organisations in Europe more choice and control of how they run AI and cloud services. EU AI Cloud is built to support organisations using SAP&#8217;s data [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/sap-outlines-new-approach-to-european-ai-and-cloud-sovereignty/"">SAP outlines new approach to European AI and cloud sovereignty</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://artificialintelligence-news.com/feed/,"AI Business Strategy, Governance, Regulation & Policy, Government & Public Sector AI, cloud, data centres, europe, sovereignty",N/A,30,True
New Microsoft cloud updates support Indonesia’s long-term AI goals,https://www.artificialintelligence-news.com/news/new-microsoft-cloud-updates-support-indonesia-long-term-ai-goals/,2025-11-26T09:36:00,Muhammad Zulhusni,"<p>Indonesia&#8217;s push into AI-led growth is gaining momentum as more local organisations look for ways to build their own applications, update their systems, and strengthen data oversight. The country now has broader access to cloud and AI tools after Microsoft expanded the services available in the Indonesia Central cloud region, which first went live six [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/new-microsoft-cloud-updates-support-indonesia-long-term-ai-goals/"">New Microsoft cloud updates support Indonesia’s long-term AI goals</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://artificialintelligence-news.com/feed/,"AI Business Strategy, AI Startups & Funding, Government & Public Sector AI, Human-AI Relationships, World of Work, cloud, government, indonesia, microsoft, software development",Microsoft,30,True
What will enter the public domain in 2026?,https://publicdomainreview.org/features/entering-the-public-domain/2026/,2025-12-02T03:23:10,N/A,"<a href=""https://news.ycombinator.com/item?id=46117112"">Comments</a>",Hacker News,https://news.ycombinator.com/rss,N/A,N/A,30,True
DeepSeek-v3.2: Pushing the frontier of open large language models [pdf],https://huggingface.co/deepseek-ai/DeepSeek-V3.2/resolve/main/assets/paper.pdf,2025-12-01T15:48:03,N/A,"<a href=""https://news.ycombinator.com/item?id=46108780"">Comments</a>",Hacker News,https://news.ycombinator.com/rss,N/A,N/A,30,True
How Brian Eno Created Ambient 1: Music for Airports (2019),https://reverbmachine.com/blog/deconstructing-brian-eno-music-for-airports/,2025-12-02T07:46:47,N/A,"<a href=""https://news.ycombinator.com/item?id=46118722"">Comments</a>",Hacker News,https://news.ycombinator.com/rss,N/A,N/A,30,True
"Codex, Opus, Gemini try to build Counter Strike",https://www.instantdb.com/essays/agents_building_counterstrike,2025-11-28T17:41:01,N/A,"<a href=""https://news.ycombinator.com/item?id=46080835"">Comments</a>",Hacker News,https://news.ycombinator.com/rss,N/A,N/A,30,True
Invisible Details of Interaction Design,https://rauno.me/craft/interaction-design,2025-11-26T10:24:56,N/A,"<a href=""https://news.ycombinator.com/item?id=46056022"">Comments</a>",Hacker News,https://news.ycombinator.com/rss,N/A,N/A,30,True
Arcee Trinity Mini: US-Trained Moe Model,https://www.arcee.ai/blog/the-trinity-manifesto?src=hn,2025-12-02T00:31:01,N/A,"<a href=""https://news.ycombinator.com/item?id=46115682"">Comments</a>",Hacker News,https://news.ycombinator.com/rss,N/A,N/A,30,True
Agentic AI autonomy grows in North American enterprises,https://www.artificialintelligence-news.com/news/agentic-ai-autonomy-grows-in-north-american-enterprises/,2025-12-01T15:53:22,Ryan Daws,"<p>North American enterprises are now actively deploying agentic AI systems intended to reason, adapt, and act with complete autonomy. Data from Digitate’s three-year global programme indicates that, while adoption is universal across the board, regional maturity paths are diverging. North American firms are scaling toward full autonomy, whereas their European counterparts are prioritising governance frameworks [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/agentic-ai-autonomy-grows-in-north-american-enterprises/"">Agentic AI autonomy grows in North American enterprises</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://www.artificialintelligence-news.com/feed/,"AI and Us, AI Business Strategy, AI Market Trends, Features, Governance, Regulation & Policy, Human-AI Relationships, Inside AI, Special Reports & Series, Trust, Bias & Fairness, World of Work, adoption, agentic ai, agents, automation, enterprise, operations, skills, strategy, trust, workforce",N/A,30,True
SAP outlines new approach to European AI and cloud sovereignty,https://www.artificialintelligence-news.com/news/sap-outlines-new-approach-to-european-ai-and-cloud-sovereignty/,2025-11-27T14:06:00,Muhammad Zulhusni,"<p>SAP is moving its sovereignty plans forward with EU AI Cloud, a setup meant to unify its efforts in the region under one approach. The goal is to give organisations in Europe more choice and control of how they run AI and cloud services. EU AI Cloud is built to support organisations using SAP&#8217;s data [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/sap-outlines-new-approach-to-european-ai-and-cloud-sovereignty/"">SAP outlines new approach to European AI and cloud sovereignty</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://www.artificialintelligence-news.com/feed/,"AI Business Strategy, Governance, Regulation & Policy, Government & Public Sector AI, cloud, data centres, europe, sovereignty",N/A,30,True
New Microsoft cloud updates support Indonesia’s long-term AI goals,https://www.artificialintelligence-news.com/news/new-microsoft-cloud-updates-support-indonesia-long-term-ai-goals/,2025-11-26T09:36:00,Muhammad Zulhusni,"<p>Indonesia&#8217;s push into AI-led growth is gaining momentum as more local organisations look for ways to build their own applications, update their systems, and strengthen data oversight. The country now has broader access to cloud and AI tools after Microsoft expanded the services available in the Indonesia Central cloud region, which first went live six [&#8230;]</p>
<p>The post <a href=""https://www.artificialintelligence-news.com/news/new-microsoft-cloud-updates-support-indonesia-long-term-ai-goals/"">New Microsoft cloud updates support Indonesia’s long-term AI goals</a> appeared first on <a href=""https://www.artificialintelligence-news.com"">AI News</a>.</p>",AI News,https://www.artificialintelligence-news.com/feed/,"AI Business Strategy, AI Startups & Funding, Government & Public Sector AI, Human-AI Relationships, World of Work, cloud, government, indonesia, microsoft, software development",Microsoft,30,True
The Machine Learning “Advent Calendar” Day 1: k-NN Regressor in Excel,https://towardsdatascience.com/day-1-k-nn-regressor-in-excel-how-distance-drives-prediction/,2025-12-01T19:52:19,angela shi,"<p>This first day of the Advent Calendar introduces the k-NN regressor, the simplest distance-based model. Using Excel, we explore how predictions rely entirely on the closest observations, why feature scaling matters, and how heterogeneous variables can make distances meaningless. Through examples with continuous and categorical features, including the California Housing and Diamonds datasets, we see the strengths and limitations of k-NN, and why defining the right distance is essential to reflect real-world structure.</p>
<p>The post <a href=""https://towardsdatascience.com/day-1-k-nn-regressor-in-excel-how-distance-drives-prediction/"">The Machine Learning “Advent Calendar” Day 1: k-NN Regressor in Excel</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Machine Learning, Algorithms, Data Science, Deep Dives, Excel, K Nearest Neighbors",N/A,30,True
The Problem with AI Browsers: Security Flaws and the End of Privacy,https://towardsdatascience.com/the-problem-with-ai-browsers-security-flaws-and-the-end-of-privacy/,2025-12-01T18:15:39,Mike Huls,"<p>How Atlas and most current AI-powered browsers fail on three aspects: privacy, security, and censorship</p>
<p>The post <a href=""https://towardsdatascience.com/the-problem-with-ai-browsers-security-flaws-and-the-end-of-privacy/"">The Problem with AI Browsers: Security Flaws and the End of Privacy</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Artificial Intelligence, Ai Safety, Browsers, Machine Learning, OpenAI, Security",N/A,30,True
Why AI Alignment Starts With Better Evaluation,https://towardsdatascience.com/why-ai-alignment-starts-with-better-evaluation/,2025-12-01T13:00:00,Hailey Quach,"<p>You can’t align what you don’t evaluate</p>
<p>The post <a href=""https://towardsdatascience.com/why-ai-alignment-starts-with-better-evaluation/"">Why AI Alignment Starts With Better Evaluation</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Large Language Models, Ai Alignment, AI Evaluation, Artificial Intelligence, Deep Dives, Llm Evaluation",N/A,30,True
Metric Deception: When Your Best KPIs Hide Your Worst Failures,https://towardsdatascience.com/metric-deception-when-your-best-kpis-hide-your-worst-failures/,2025-11-29T15:00:00,Shafeeq Ur Rahaman,"<p>The most dangerous KPIs aren’t broken; they’re the ones trusted long after they’ve lost their meaning.</p>
<p>The post <a href=""https://towardsdatascience.com/metric-deception-when-your-best-kpis-hide-your-worst-failures/"">Metric Deception: When Your Best KPIs Hide Your Worst Failures</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Data Science, Dashboard, Data Visualization, Editors Pick, Machine Learning, Statistics",N/A,30,True
How to Scale Your LLM Usage,https://towardsdatascience.com/how-to-scale-your-llm-usage/,2025-11-29T13:00:00,Eivind Kjosbakken,"<p>Learn how to increase LLM usage to achieve increased productivity</p>
<p>The post <a href=""https://towardsdatascience.com/how-to-scale-your-llm-usage/"">How to Scale Your LLM Usage</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Agentic AI, Ai Scaling, ChatGPT, Gemini, Llm, LLM Agents",N/A,30,True
The Product Health Score: How I Reduced Critical Incidents by 35% with Unified Monitoring and n8n Automation,https://towardsdatascience.com/the-product-health-score-how-i-reduced-critical-incidents-by-35-with-unified-monitoring-and-n8n-automation/,2025-11-28T12:30:00,Yassin Zehar,"<p>How product, growth and engineering teams can converge on a single signal for better incident management</p>
<p>The post <a href=""https://towardsdatascience.com/the-product-health-score-how-i-reduced-critical-incidents-by-35-with-unified-monitoring-and-n8n-automation/"">The Product Health Score: How I Reduced Critical Incidents by 35% with Unified Monitoring and n8n Automation</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Product Management, Artificial Intelligence, Automation, Data Science, n8n, SaaS",N/A,30,True
"Neural Networks Are Blurry, Symbolic Systems Are Fragmented. Sparse Autoencoders Help Us Combine Them.",https://towardsdatascience.com/neuro-symbolic-systems-the-art-of-compromise-2/,2025-11-27T17:24:06,Xiaocong Yang,"<p>Neural and symbolic models compress the world in fundamentally different ways, and Sparse Autoencoders (SAEs) offer a bridge to connect them.</p>
<p>The post <a href=""https://towardsdatascience.com/neuro-symbolic-systems-the-art-of-compromise-2/"">Neural Networks Are Blurry, Symbolic Systems Are Fragmented. Sparse Autoencoders Help Us Combine Them.</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Deep Learning, Artificial Intelligence, Deep Dives, Machine Learning, Neural Network, Sparse Autoencoder",N/A,30,True
"Water Cooler Small Talk, Ep. 10: So, What About the AI Bubble?",https://towardsdatascience.com/water-cooler-small-talk-ep-10-so-what-about-the-ai-bubble/,2025-11-27T15:30:00,Maria Mouschoutzi,"<p>Have we all been tricked into believing in an impossible, extremely expensive future?</p>
<p>The post <a href=""https://towardsdatascience.com/water-cooler-small-talk-ep-10-so-what-about-the-ai-bubble/"">Water Cooler Small Talk, Ep. 10: So, What About the AI Bubble?</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Artificial Intelligence, Editors Pick, Hype Cycle, Machinelearning, Technology",N/A,30,True
Everyday Decisions are Noisier Than You Think — Here’s How AI Can Help Fix That,https://towardsdatascience.com/everyday-decisions-are-noisier-than-you-think-heres-how-ai-can-help-fix-that/,2025-11-27T14:00:00,Sean Moran,"<p>From insurance premiums to courtrooms: the impact of noise</p>
<p>The post <a href=""https://towardsdatascience.com/everyday-decisions-are-noisier-than-you-think-heres-how-ai-can-help-fix-that/"">Everyday Decisions are Noisier Than You Think — Here’s How AI Can Help Fix That</a> appeared first on <a href=""https://towardsdatascience.com"">Towards Data Science</a>.</p>",Towards Data Science,https://towardsdatascience.com/feed,"Data Science, Artificial Intelligence, Bias Variance Tradeoff, Decision Making, Editors Pick, Noise",N/A,30,True
DeepSeek Math V2 Guide: Smarter AI for Real Math,https://www.analyticsvidhya.com/blog/2025/12/deepseek-math-v2/,2025-12-01T17:44:09,Riya Bansal,"<p>If you’ve been following the AI space lately, you’ve probably noticed something big: people don’t just care&#160;what&#160;an AI answers anymore, they care&#160;how&#160;it reaches that answer. And that’s exactly where DeepSeek Math V2 steps in. It’s an open-source model built specifically for real mathematical reasoning. In this guide, I’ll walk you through what DeepSeek Math V2 [&#8230;]</p>
<p>The post <a href=""https://www.analyticsvidhya.com/blog/2025/12/deepseek-math-v2/"">DeepSeek Math V2 Guide: Smarter AI for Real Math</a> appeared first on <a href=""https://www.analyticsvidhya.com"">Analytics Vidhya</a>.</p>",Analytics Vidhya,https://www.analyticsvidhya.com/feed/,"Beginner, GenAI Tools, Generative AI, LLMs",N/A,30,True
7 Latest AI Drops by Google Will Make You a Powerhouse at Work,https://www.analyticsvidhya.com/blog/2025/11/google-ai-drops/,2025-11-28T11:38:36,Sarthak Dogra,"<p>Google has just dropped its biggest wave of AI updates in months. The best part &#8211; each one rewires how we get things done. And to add to that, this range of AI tools and features span across generating content, solving problems, and even getting multi-step, complicated tasks done by the power of AI. From [&#8230;]</p>
<p>The post <a href=""https://www.analyticsvidhya.com/blog/2025/11/google-ai-drops/"">7 Latest AI Drops by Google Will Make You a Powerhouse at Work</a> appeared first on <a href=""https://www.analyticsvidhya.com"">Analytics Vidhya</a>.</p>",Analytics Vidhya,https://www.analyticsvidhya.com/feed/,"Beginner, GenAI Tools, Generative AI",Google,30,True
